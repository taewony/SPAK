============================================================
▶️  Running [1/3]: Exp1_Baseline_RoPE_Fixed
    Script: train_baseline_12l.py
    Output: experiments/Exp1_Baseline_RoPE_Fixed
============================================================

[CMD] python train_baseline_12l.py --dataset=addition_reverse --n_layer=12 --n_embd=256 --n_head=4 --max_iters=15000 --batch_size=128 --weight_decay=1e-4 --out_dir=experiments/Exp1_Baseline_RoPE_Fixed
Overriding: dataset = addition_reverse
Overriding: n_layer = 12
Overriding: n_embd = 256
Overriding: n_head = 4
Overriding: max_iters = 15000
Overriding: batch_size = 128
Overriding: weight_decay = 0.0001
Overriding: out_dir = experiments/Exp1_Baseline_RoPE_Fixed
Indexing newlines for aligned batching...
Starting 12L Baseline Training on addition_reverse...
step 0: train loss 2.6694, val loss 2.6673, lr 0.0000e+00
iter 0: loss 2.6695, time 12365.12ms
iter 100: loss 1.8855, time 37.03ms
iter 200: loss 1.5738, time 33.28ms
iter 300: loss 1.1877, time 32.08ms
iter 400: loss 1.0510, time 31.99ms
step 500: train loss 0.1691, val loss 0.1694, lr 9.9840e-04
iter 500: loss 0.3136, time 109.63ms
iter 600: loss 0.1148, time 32.01ms
iter 700: loss 0.0587, time 67.83ms
iter 800: loss 0.0391, time 32.07ms
iter 900: loss 0.0245, time 32.03ms
step 1000: train loss 0.0078, val loss 0.0076, lr 9.9192e-04
