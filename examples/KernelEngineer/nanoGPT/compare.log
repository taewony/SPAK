python compare_deep.py
number of parameters: 29.94M
--- Deep Block-by-Block Comparison (T=10) ---
Embeddings Diff: 0.000000e+00
Block 0 Diff: 6.135803e+00
Block 1 Diff: 6.787292e+00
Block 2 Diff: 6.937214e+00
Block 3 Diff: 6.903868e+00
Block 4 Diff: 7.083340e+00
Block 5 Diff: 7.223535e+00
Final LN Diff: 3.163020e+00
Final Logits Diff: 7.964844e+00
--- Greedy Sampling (Top-1) Comparison ---
/pytorch/aten/src/ATen/native/cuda/TensorCompare.cu:112: _assert_async_cuda_kernel: block: [0,0,0], thread: [0,0,0] Assertion `probability tensor contains either `inf`, `nan` or element < 0` failed.
Traceback (most recent call last):
  File "/home/linux/taewony/SPAK/examples/KernelEngineer/nanoGPT/compare_deep.py", line 90, in <module>
    compare_deep()
  File "/home/linux/taewony/SPAK/examples/KernelEngineer/nanoGPT/compare_deep.py", line 74, in compare_deep
    y_ct = model_ct.generate(x[:, :1], 20, temperature=1.0, top_k=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/linux/taewony/env/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/linux/taewony/SPAK/examples/KernelEngineer/nanoGPT/nanogpt_cutile.py", line 269, in generate
    logits, _ = self(idx_cond)
                ^^^^^^^^^^^^^^
  File "/home/linux/taewony/env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/linux/taewony/env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/linux/taewony/SPAK/examples/KernelEngineer/nanoGPT/nanogpt_cutile.py", line 261, in forward
    logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
                          ~^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
