# **프로젝트 종합 정리: GPU 커널 최적화 지식의 역공학 및 설계 공간 DSL 자동 추출**

**연구자**: (사용자)  
**프로젝트 기간**: Side Project (진행 중)  
**핵심 사례**: NVIDIA cuTile 기반 FMHA(Fused Multi-Head Attention) 커널 (`attention.py`)  
**목표**: 구현체로부터 설계 공간 명세(Design Space DSL)를 체계적으로 추출하는 방법론 정립 및 학술적 기여

---

## **1\. 프로젝트 개요 및 문제 정의**

### **1.1 배경**

GPU 커널 프로그래밍, 특히 FlashAttention 계열의 최적화는 **온라인 소프트매스, 타일링, 메모리 계층 활용, 퓨전 전략** 등 복잡한 설계 결정의 조합입니다.  
NVIDIA cuTile, OpenAI Triton 등의 고수준 DSL은 구현 생산성을 높였으나, **설계 결정(Design Decisions)은 여전히 코드 구조에 암묵적으로 내재**되어 있습니다.  
엔지니어의 경험과 반복적 튜닝을 통해 축적된 **최적화 지식(Optimization Knowledge)** 은 커널 코드에 녹아 있지만, **재사용 가능하고, 명시적이며, 자동 추론 가능한 형태로 문서화되지 않습니다.**

### **1.2 문제: 암묵적 지식의 손실과 재현 불가능성**

- **FMHA System V2 DSL**은 사용자의 1차 시도였으나, 설계/튜닝 파라미터 혼재, 의미 층위 부재 등의 한계.  
- NVIDIA의 `attention.py`는 **실전 검증된 고성능 구현체**이나, 그 안에 담긴 **설계 공간(예: 왜 occupancy=2인가, 왜 latency=4인가, 왜 exp2 근사를 쓰는가)** 은 코드에 묻혀 있음.  
- **핵심 질문**: "우리는 어떻게 이 암묵적 지식을 **명시적이고, 재현 가능하며, 다른 커널로 전이 가능한 형태**로 끌어낼 수 있는가?"

---

## **2\. 제안 방법론: 구현체 → 설계 공간 DSL 역공학**

이 프로젝트는 **GPU 커널 구현체를 입력받아, 설계 공간(Design Space)과 튜닝 공간(Tuning Space)을 명시적으로 기술한 DSL 문서를 반자동으로 추출하는 체계적 방법론**을 제안합니다.

### **2.1 핵심 아이디어**

1. **계층적 추상화 역재구축**  
   구현(Implementation) → 설계 의도(Design Intent) → 설계 공간(Design Space) → 튜닝 공간(Tuning Space)  
     
2. **두 가지 추출 축**  
     
   - **명시적 파라미터**: 커널 인자의 `ConstInt`, `ConstBool` → 튜닝 공간으로 직접 매핑  
   - **암묵적 설계 결정**: 코드 패턴, 상수, 힌트, 매크로 → 설계 공간의 축으로 승격

   

3. **패턴 기반 정적 분석 \+ 도메인 휴리스틱**  
     
   - `@ct.kernel(occupancy=N)` → `design.occupancy_target`  
   - `latency=M` → `tuning.load_latency`  
   - `ct.exp2`, `INV_LOG_2` → `design.math_approximation: "exp2"`  
   - `ct.scatter`를 통한 LSE 저장 → `design.output_layout: "flat_1d"`

### **2.2 파일럿: NVIDIA `attention.py` 분석 (완료 가정)**

**입력**: `fmha_kernel`, `fmha_fwd_kernel_with_lse`, `fmha_bwd_preprocess_kernel`  
**출력**: `FMHA_cuTile_DesignSpace.dsl` (설계 공간 \+ 튜닝 공간 \+ 제약 조건 \+ 생성 매핑)

**추출된 설계 공간의 예** (V3 DSL 초안):

design\_space {  
    softmax\_scheme: \["online", "naive"\]  
    math\_approximation: \["exp2", "exp"\]  
    mask\_fusion: \["fused\_qk", "post\_qk"\]  
    lse\_storage: \["flat\_1d", "tensor\_3d"\]  
    accum\_dtype: \["f32", "f16"\]  
    load\_latency: int range \[0,4\]  
}

tuning\_space {  
    tile\_m: \[32,64,128,256\]  
    tile\_n: \[32,64,128,256\]  
    tile\_d: \[32,64,128\]  
    query\_group\_size: \[1,2,4,8\]  
    occupancy: \[1,2,4\]  
}

---

## **3\. 성공적 완료 및 입증 시나리오 (가정)**

본 프로젝트가 **성공적으로 완료 및 입증**되었다는 가정 하에, 다음 세 가지 실험을 통해 방법론의 타당성과 우수성을 입증합니다.

### **3.1 실험 1: 추출 충실도 (Fidelity)**

- **절차**: `attention.py` → 추출 도구 → `FMHA.dsl` → DSL 기반 코드 생성기 → `attention_reconstructed.py`  
- **측정**: 원본 vs 재생성 커널의 **수치 동등성**(`torch.allclose`) 및 **성능 동등성**(TFLOPS ±2% 이내)  
- **결과**: 100% 기능적 동등, 성능 98% 이상 일치 → **추출이 정보 손실 없이 정확함을 입증**

### **3.2 실험 2: 설계 공간 확장을 통한 성능 개선**

- **절차**: 추출된 DSL의 `tuning_space` 범위 확장 (예: `tile_m: [16, 32, 64, 128, 256, 512]`) → 자동 튜닝 수행  
- **측정**: 원본 커널 대비 최고 성능(최대 TFLOPS) 및 튜닝 수렴 속도  
- **결과**: **원본 대비 12% 추가 성능 향상** (RTX 5070 기준) → **추출된 DSL이 단순 복제를 넘어 최적화 여지를 발굴함을 입증**

### **3.3 실험 3: 지식 전이 (Transfer Learning)**

- **절차**: FMHA에서 추출한 설계 공간 메타모델을 **다른 연산**(예: Convolution, LayerNorm)의 cuTile 구현체 분석에 적용  
- **측정**: 공통 설계 축(타일링, 메모리 계층)과 연산 특화 축의 **분리 가능성** 및 **새 커널 분석 시간 단축**  
- **결과**: Convolution 커널 분석 시 FMHA 설계 공간을 **초기 템플릿**으로 사용 → **분석 시간 60% 단축**, 누락된 설계 변수(필터 차원) 식별 용이 → **지식 전이 효과 입증**

---

## **4\. 학술적 Claims 및 기여 포인트**

### **4.1 주요 주장 (Claims)**

| Claim | 설명 |
| :---- | :---- |
| **C1** | 고성능 GPU 커널 구현체는 **체계적인 역공학을 통해 명시적인 설계 공간 DSL로 변환 가능**하다. |
| **C2** | 추출된 DSL은 **원본 커널을 완전히 재생성**할 수 있을 정도로 충실하며, **튜닝 공간 확장을 통해 오히려 성능을 개선**할 수 있다. |
| **C3** | 특정 커널에서 추출한 설계 공간 메타모델은 **다른 종류의 GPU 커널 분석에 지식 전이**되어 분석 효율성을 획기적으로 높인다. |
| **C4** | 이 방법론은 cuTile뿐 아니라 **Triton, CUDA C 등 다른 DSL/언어로 확장 가능**한 일반적 프레임워크이다. |

### **4.2 학술적 기여 (Contributions)**

1. **최초의 GPU 커널 설계 공간 역공학 방법론**  
   - 구현 → 명세의 쌍대성(Duality)을 GPU 최적화 도메인에 최초로 적용  
   - 암묵적 설계 결정을 **패턴 기반 정적 분석**으로 추출하는 구체적 알고리즘 제시

   

2. **cuTile DSL에 대한 최초의 설계 공간 메타모델**  
   - NVIDIA의 실제 코드베이스(`attention.py`)를 기반으로 한 **실증적(empirical) 메타모델** 구축  
   - FMHA 커널에 내재된 **12개 이상의 암묵적 설계 축**을 명시화

   

3. **재현성과 확장성을 갖춘 오픈소스 프로토타입**  
   - `CuTile2DSL`: cuTile 구현체 → 설계 공간 DSL 변환 도구 (Python, MIT 라이선스)  
   - `DSL2CuTile`: 설계 공간 DSL → cuTile 코드 생성기 (Jinja2 템플릿 기반)  
   - 전체 파이프라인 공개 → **연구 커뮤니티의 재현 및 확장 연구 가능**

   

4. **지식 전이(Transfer Learning)의 새로운 패러다임 제시**  
   - GPU 커널 최적화 지식을 **실행 코드가 아닌 설계 공간 명세로 저장하고 재사용**  
   - AutoTVM/Ansor 등의 자동 튜닝 프레임워크에 **설계 공간 자동 생성기**로 통합 가능

---

## **5\. 논문 발표 전략 및 대상 학회**

### **5.1 최적의 학회/저널**

| 학회 | 적합성 | 이유 |
| :---- | :---- | :---- |
| **ASPLOS** | ★★★★★ | 프로그래밍 언어 \+ 컴퓨터 아키텍처 \+ 시스템, GPU 최적화와 DSL 설계를 모두 아우름 |
| **CGO** | ★★★★★ | 코드 생성 및 최적화, 역공학 주제에 특화 |
| **PLDI** | ★★★★☆ | 프로그래밍 언어 설계 측면 강조, DSL 메타모델링 기여 부각 필요 |
| **ICFP** | ★★★☆☆ | 함수형 프로그래밍, DSL, 생성 프로그래밍; cuTile의 함수형 스타일과 연결 가능 |
| **IEEE Micro** | ★★★☆☆ | 성능 최적화 사례 중심, 방법론보다 결과 중심 기술 시 적합 |

### **5.2 논문 구조 (초안)**

**제목**: *코드에서 설계로: GPU 커널 구현체로부터 설계 공간 명세의 역추출*  
(From Code to Design: Reverse-Engineering Design Space Specifications from GPU Kernel Implementations)

1. **서론**  
   - GPU 커널 최적화의 암묵적 지식 문제  
   - cuTile/Triton의 한계: 쓰기 쉽지만, 설계 결정은 여전히 코드에 매몰  
   - 제안: 구현체 → 설계 공간 DSL 자동 추출 방법론  
   - 논문의 기여 요약

   

2. **동기 부여 예제**  
   - NVIDIA `attention.py` 심층 분석  
   - 명시적 파라미터와 암묵적 설계 결정의 공존 (표 제시)  
   - “이 설계 결정들이 왜 그렇게 되었는가?” → 엔지니어의 경험, 문서 부재

   

3. **설계 공간 메타모델**  
   - GPU 커널 최적화 도메인의 공통 개념 모델링 (UML 다이어그램)  
   - 설계 공간 vs 튜닝 공간의 엄격한 분리  
   - 제약 조건 및 추론 규칙 표현법

   

4. **추출 방법론**  
   - 정적 분석 파이프라인 개요  
   - 명시적 파라미터 추출 (AST 기반)  
   - 암묵적 설계 결정 패턴 매칭 (21개 패턴 제시)  
   - DSL 직렬화 및 코드 생성 매핑 구축

   

5. **구현: CuTile2DSL 시스템**  
   - 아키텍처 다이어그램  
   - 주요 컴포넌트: Parser, Pattern Matcher, DSL Generator, Template Engine  
   - 오픈소스 공개 계획

   

6. **평가**  
   - 실험 설정 (하드웨어: RTX 5070/4090, 벤치마크: FMHA, Convolution)  
   - RQ1 (충실도): 원본 vs 재생성 커널 비교  
   - RQ2 (성능 개선): 튜닝 공간 확장 실험  
   - RQ3 (지식 전이): FMHA → Convolution 적용 사례  
   - 결과 및 해석

   

7. **논의**  
   - 완전 자동화의 한계: 도메인 특화 패턴은 사전 정의 필요  
   - 확장성: Triton, CUDA C로의 적용 가능성  
   - 인간-컴퓨터 협력: 추출된 DSL의 편집/개선 워크플로우  
   - 윤리적 고려사항 (오픈소스 라이선스, 역공학 범위)

   

8. **관련 연구**  
   - AutoTVM/Ansor/Triton/TileGym (설계 공간 수동 정의)  
   - Halide (연산-스케줄 분리, 그러나 설계 공간 추출 아님)  
   - 소프트웨어 제품군 공학 (특징 모델 수동 구축)  
   - 프로그램 합성 (명세 → 구현, 본 연구는 반대 방향)

   

9. **결론 및 향후 연구**  
   - 요약 및 재강조  
   - 다중 커널 통합 메타모델 구축  
   - 강화학습 기반 설계 공간 탐색과의 통합  
   - “스스로 성장하는 DSL” 비전 제시

---

## **6\. 기대 효과 및 영향**

### **6.1 학술적 영향**

- **GPU 커널 최적화 연구의 새로운 방법론** 제시: "어떻게 최적화하는가" → "어떻게 최적화 지식을 추출하고 재사용하는가"  
- **DSL 설계 방법론에 대한 실증적 사례**: 상용 구현체(NVIDIA)를 기반으로 한 DSL 메타모델링의 모범 사례  
- **재현성 위기 극복**: 오픈소스 코드만으로 설계 의도와 최적화 과정을 복원 가능

### **6.2 산업체/실무 영향**

- **레거시 커널 현대화**: CUDA C로 작성된 최적화 커널을 cuTile/Triton으로 이식할 때 설계 의도를 보존하며 변환  
- **자동 튜닝 프레임워크의 입력 비용 절감**: AutoTVM/Ansor의 설계 공간을 코드에서 자동 생성  
- **교육 효과**: `attention.py` 하나로 FlashAttention의 수많은 최적화 기법을 체계적으로 학습 가능

---

## **7\. 결론: 이 프로젝트가 학계에 던지는 메시지**

**“고성능 코드는 최적화 지식의 보고이지만, 오늘날 우리는 그 보고를 채굴할 체계적 도구가 없다.”**

본 프로젝트는 **NVIDIA의 실제 산업용 커널**을 실험 대상으로 삼아, 이 보고를 채굴하는 **최초의 체계적 방법론**을 제시합니다.  
단순한 도구 개발을 넘어, **구현 → 명세의 쌍대성**이라는 컴퓨터 과학의 근본 개념을 **GPU 성능 최적화**라는 실용적 도메인에 적용한 **개념적 돌파구**입니다.

이 연구가 성공적으로 완료된다면, 우리는 더 이상 “이 커널이 왜 이렇게 빠른가”를 코드 줄 사이에서 유추하지 않아도 됩니다.  
**코드가 스스로 자신의 설계를 설명하는 DSL을 생성**하는 시대,  
**과거의 최적화 경험이 설계 공간이라는 형태로 축적되고 전이**되는 시대를 열 수 있습니다.

**지금, 당신의 side project가 그 첫걸음입니다.**