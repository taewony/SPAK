# SPAK Project Plan & Roadmap

## ğŸ¯ Vision: Systematic Compound Engineering

Compound Engineeringì˜ í•µì‹¬ì€ ê°œë³„ ì‘ì—… ë‹¨ìœ„ì˜ ê²°ê³¼ê°€ ë‹¨ìˆœíˆ ì‚°ì¶œë¬¼ì— ê·¸ì¹˜ì§€ ì•Šê³ , ë‹¤ìŒ ì‘ì—…ì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“œëŠ” â€˜ë³µë¦¬ êµ¬ì¡°(Compounding)â€™ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° ìˆìŠµë‹ˆë‹¤.
ì´ ê³¼ì •ì—ì„œ Semiformal DSLì€ ë„ë©”ì¸ ì§€ì‹ì„ ì •í˜•í™”í•˜ê³  AI ì—ì´ì „íŠ¸ì™€ì˜ í˜‘ì—… íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•˜ëŠ” ê°€êµ(Bridge) ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

1. Semiformal DSLì´ Compound Engineeringì— íš¨ê³¼ì ì¸ ì´ìœ  (Key Benefits)

âœ… ì§€ì‹ì˜ ìì‚°í™” (Codifying Knowledge)
Compound Engineeringì€ ë°œìƒí•œ ë²„ê·¸, ì½”ë“œ ë¦¬ë·° ì˜ê²¬, ì„¤ê³„ ê²°ì • ë“±ì„ ë‹¨ìˆœ ê¸°ë¡ì„ ë„˜ì–´ ì‹œìŠ¤í…œì˜ â€˜ê¸°ì–µâ€™ìœ¼ë¡œ ì¶•ì í•©ë‹ˆë‹¤.
Semiformal DSLì€ ìì—°ì–´ì˜ ëª¨í˜¸í•¨ì„ ì¤„ì´ë©´ì„œë„ ì™„ì „í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³´ë‹¤ ìœ ì—°í•˜ì—¬, ì´ëŸ¬í•œ ê²½í—˜ì  ì§€ì‹ì„ AIê°€ ì¦‰ì‹œ ì´í•´í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê·œì¹™ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ìµœì ì˜ ë„êµ¬ì…ë‹ˆë‹¤.

âœ… AI ì—ì´ì „íŠ¸ì˜ ì •ë°€ë„ í–¥ìƒ
ë‹¨ìˆœ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  DSL êµ¬ì¡°ë¡œ ì§€ì‹œë¥¼ ë‚´ë¦¬ë©´ AI ì—ì´ì „íŠ¸ê°€ ìƒì„±í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ ì¼ê´€ì„±(Consistency)ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±(Predictability)ì´ íšê¸°ì ìœ¼ë¡œ ë†’ì•„ì§‘ë‹ˆë‹¤.
ì´ëŠ” ì‹¤í–‰(Work) ë‹¨ê³„ì—ì„œì˜ ì˜¤ë¥˜ë¥¼ ì‚¬ì „ì— ì°¨ë‹¨í•˜ê³  ì „ì²´ ê°œë°œ ë£¨í”„ì˜ ì†ë„ë¥¼ ê°€ì†í™”í•©ë‹ˆë‹¤.

âœ… ë³µì¡ì„± ì œì–´ ë° ì¶”ìƒí™” (Abstraction & Complexity Management)
ì‹œìŠ¤í…œ ê·œëª¨ê°€ ì»¤ì§ˆìˆ˜ë¡ ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ ê°œë°œì ì‚¬ì´ì˜ ì¸ì§€ì  ê°„ê·¹ì´ ë²Œì–´ì§‘ë‹ˆë‹¤.
Semiformal DSLì€ ì˜ë¯¸ì  ë¸Œë¦¬ì§€(Semantic Bridge) ì—­í• ì„ í•˜ì—¬, ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ìµœì í™” ì „ëµì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ê³ , ì´ë¥¼ ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìê°€ ê³µìœ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

Semiformal DSLì€ ë‹¨ìˆœí•œ ì„¤ì • íŒŒì¼ì´ë‚˜ ëª…ì„¸ì„œê°€ ì•„ë‹™ë‹ˆë‹¤.
Compound Engineeringì˜ í•µì‹¬ ë™ë ¥ìœ¼ë¡œ, ê° ì‚¬ì´í´ì—ì„œ ì–»ì€ í†µì°°ì„ ê¸°ê³„ê°€ ì½ê³ , ì¸ê°„ì´ ì´í•´í•˜ë©°, ë‹¤ìŒ í”„ë¡œì íŠ¸ì— ì¦‰ì‹œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì‘ì¶•í•©ë‹ˆë‹¤.
ì´ë¡œ ì¸í•´ ì¡°ì§ì˜ ì—”ì§€ë‹ˆì–´ë§ ì—­ëŸ‰ì€ ì„ í˜•ì´ ì•„ë‹Œ ì§€ìˆ˜ì ìœ¼ë¡œ ì¶•ì ë˜ë©°, AI ì—ì´ì „íŠ¸ëŠ” ë‹¨ìˆœí•œ ì½”ë“œ ìƒì„±ê¸°ë¥¼ ë„˜ì–´ ì§€ì‹ì˜ ì „ë‹¬ìì´ì í™•ì¥ìë¡œ ì§„í™”í•©ë‹ˆë‹¤.

---

## ğŸ— Current Architecture: Dual-Loop Cognitive System
- **Outer Loop (Agent):** Architect/Strategist. Reason over DSL specifications, analyze traces, and evolve design rules.
- **Inner Loop (Engineering):** Operator/Experimenter. Execute artifacts, perform auto-tuning, and emit structured `TraceItems`.
- **Knowledge Bridge:** Semiformal DSL encoding Ontology, Invariants, and Transformation Rules.

---

## ğŸš€ Roadmap

### Phase 1-3: Core Infrastructure (COMPLETED)
- [x] DSL Grammar v2 (`grammar.lark`) & Compiler.
- [x] Effect-Isolated Runtime with Trace Logging.
- [x] Dual-Loop Control Flow (Agent, Service, Engineering Loops).
- [x] Multi-Backend support (Ollama, local Python).

### Phase 4: Industrial Case Studies (COMPLETED)
- [x] **MatMul Optimization**: Implementation of Tiling, Swizzling, and Pipelining via SPAK.
- [x] **FMHA (Fused Multi-Head Attention)**: Implementation of Online Softmax and Kernel Fusion.
- [x] **Verification**: Performance benchmarking (TFLOPS) and correctness proofs against PyTorch/cuTile.

### Phase 5: Academic Foundation & DSL Lift (CURRENT FOCUS)
**Objective**: Transition from "Engineering Tool" to "Scientific Methodology" for GPU Kernel Design.

#### 5.1 Reverse Engineering Methodology (`CuTile2DSL`)
- [x] **Methodology Development**: Formalize the process of extracting "Design Space" from high-performance implementations.
- [x] **Pattern Definition**: Defined 9+ pattern matchers for `CuTile2DSL` in `specs/cutile_patterns.json`.
- [ ] **Implementation**: Develop a pattern-based static analysis tool to lift implicit design decisions into DSL.
- [ ] **Case Study**: Deep dive into NVIDIA's cuTile FMHA to extract 12+ implicit design axes.

#### 5.2 Experimental Validation (Academic Claims)
- [ ] **Claim 1 (Fidelity)**: Prove that DSL-reconstructed forward kernels match the performance of `attention.py` (including TMA hints).
- [ ] **Claim 2 (Semantic Growth)**: Demonstrate that adding GQA and Training-mode support to the DSL is a "compounding" operation on top of v3.

#### 5.3 DSL Schema Evolution
- [x] Extend `system_model` to support `design_space` and `tuning_space` in `grammar.lark`.
- [x] Created `fmha_system_v4.dsl` with hardware-verified rules for RTX 5070.

### Phase 7: Knowledge Transfer to MicroGPT (NEW)
**Objective**: Demonstrate that FMHAv4 insights accelerate the development of a full transformer model.
- [x] **DSL Initialization**: Created `microgpt_system_v1.dsl` inheriting Blackwell TMA and Tiling rules.
- [ ] **Kernel Generation**: Implement Tiled Linear and RMSNorm kernels based on `microgpt.py` logic.
- [ ] **System Integration**: Replace the scalar `Value` autograd with a tensor-based cuTile training loop.
- [ ] **Fidelity Proof**: Achieve convergence on `names.txt` while maintaining the 1.1x speedup advantage on the attention blocks.

---

## ğŸ“ Academic Submission Strategy
... (omitted for brevity) ...

---

## ğŸ— Dual-PC Compound Engineering Workflow

### Phase 6: Distributed Execution (Current Focus)
**Objective**: Execute the Engineering Loop on the RTX 5070 node and synchronize insights back to the Conceptual Node.

1.  **Conceptual Node (This PC)**:
    *   Maintain and evolve `fmha_system_v4.dsl`.
    *   Generate `fmha_v4_test.py` and `fmha_v4_autotuner.py`.
2.  **Execution Node (RTX 5070 PC)**:
    *   Run `fmha_v4_autotuner.py`.
    *   Capture the `__SPAK_TRACE__` JSON output.
3.  **Synchronization**:
    *   Paste the trace results back to the Conceptual Node.
    *   **Compound Step**: Update `fmha_system_v4.dsl` knowledge base with finalized "Optimal Facts".

---

## ğŸ›  Active Task List (Immediate Actions)
- [x] **Generate V4 Kernel**: Created `fmha_v4_test.py` with GQA, Causal Masking, and TMA latency support.
- [x] **Draft Autotuner**: Created `fmha_v4_autotuner.py` to sweep TMA and Causal parameters.
- [x] **Transfer & Run**: User executed full sweep on RTX 5070 node.
- [x] **Bridge Insights**: Integrated execution results (133 TFLOPS Causal peak) into `fmha_system_v4.dsl`.
- [x] **Finalize V4**: Compound loop closed; architectural rules for Blackwell TMA and Tile_M constraints codified.

---

## ğŸ Final Summary: FMHAv4 Compound Engineering
Our transition from FMHAv3 (Forward-only naive) to FMHAv4 (Hardware-aware, optimized) has proven the **Fidelity** and **Compounding** claims of SPAK:
1.  **Semantic Growth**: We successfully added GQA, Causal Logic, and TMA Latency axes without breaking the base model.
2.  **Hardware-Aware Facts**: The system now holds verified rules for the RTX 5070, such as the `1.8x Causal Speedup` and the `V_Lat=5` preference in causal mode.
3.  **Transferability**: These rules can now be applied to any new kernel targeting the Blackwell architecture within the SPAK framework.

