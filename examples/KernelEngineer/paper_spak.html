<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SPAK: Progressive GPU Kernel Engineering for Recurrent Intelligence</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #34495e;
            --accent-color: #3498db;
            --bg-color: #f4f7f6;
            --paper-bg: #ffffff;
            --text-color: #333333;
            --border-color: #e0e6ed;
        }
        body {
            font-family: 'Times New Roman', Times, 'KoPub Batang', 'Malgun Gothic', serif;
            line-height: 1.7;
            color: var(--text-color);
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
            background-color: var(--bg-color);
        }
        .paper-container {
            background-color: var(--paper-bg);
            padding: 70px 80px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.08);
            border-radius: 8px;
        }
        h1 { text-align: center; font-size: 2.4em; margin-bottom: 10px; color: var(--primary-color); letter-spacing: -0.5px; }
        h2 { border-bottom: 2px solid var(--secondary-color); margin-top: 50px; padding-bottom: 8px; color: var(--primary-color); font-size: 1.5em; }
        h3 { color: var(--secondary-color); margin-top: 30px; font-size: 1.25em; }
        h4 { text-align: center; color: #7f8c8d; margin-top: 5px; font-weight: normal; font-style: italic; font-size: 1.1em; }
        .authors { text-align: center; font-variant: small-caps; margin-bottom: 40px; font-size: 1.15em; font-weight: bold; color: var(--secondary-color); }
        
        .abstract { 
            background: #fdfdfd; 
            padding: 25px 35px; 
            font-size: 0.95em; 
            border-left: 4px solid var(--secondary-color);
            margin: 30px 0;
            text-align: justify;
            box-shadow: 0 2px 10px rgba(0,0,0,0.02);
        }
        
        table { 
            width: 100%; 
            border-collapse: collapse; 
            margin: 35px 0; 
            font-family: 'Arial', sans-serif;
            font-size: 0.95em;
        }
        th, td { border: 1px solid var(--border-color); padding: 14px; text-align: center; }
        th { background-color: #f8f9fa; font-weight: bold; color: var(--primary-color); }
        .highlight-row { background-color: #fffde7; font-weight: bold; }
        
        .figure { text-align: center; margin: 45px 0; }
        .figure img { max-width: 90%; height: auto; border: 1px solid var(--border-color); box-shadow: 0 4px 15px rgba(0,0,0,0.05); border-radius: 4px; }
        .figure-caption { font-style: italic; font-size: 0.9em; margin-top: 15px; padding: 0 40px; color: #555; line-height: 1.5; }
        
        code { background: #f4f6f7; padding: 3px 6px; font-family: 'Consolas', 'Courier New', monospace; border-radius: 3px; font-size: 0.9em; color: #c0392b; }
        .formula { text-align: center; margin: 25px 0; font-size: 1.2em; overflow-x: auto; }
        
        .case-description { background: #fcfcfc; padding: 25px; border-left: 4px solid var(--primary-color); margin: 25px 0; font-size: 0.95em; border-radius: 0 4px 4px 0; }
        .insight-box { background-color: #eaf2f8; border-left: 4px solid var(--accent-color); padding: 20px 25px; margin: 25px 0; border-radius: 0 4px 4px 0; }
        .insight-box h4 { text-align: left; margin-top: 0; color: #2980b9; margin-bottom: 12px; font-weight: bold; font-style: normal; }
        
        .appendix-code { background: #272822; color: #f8f8f2; padding: 25px; overflow-x: auto; border-radius: 5px; font-family: 'Consolas', monospace; font-size: 0.85em; line-height: 1.5; margin-top: 20px; }
        
        .divider { margin: 60px 0; border: 0; border-top: 2px dashed #bdc3c7; }
        
        @media (max-width: 768px) {
            .paper-container { padding: 30px; }
            .figure img { max-width: 100%; }
        }
    </style>
</head>
<body>

<div class="paper-container">
    <h1>Progressive Evolution of GPU Kernels from MatMul to Recurrent Intelligence</h1>
    <h4>SPAK: Systematic Paradigms for Agent based Kernel engineering</h4>
    <div class="authors">The SPAK Research & Engineering Team</div>

    <div class="abstract">
        <strong>Abstract:</strong> This report details the progressive engineering journey of high-performance GPU kernels, starting from fundamental matrix operations to recurrent language models. We developed the <strong>LoopLM</strong> architecture, which utilizes temporal recurrence instead of spatial depth to achieve superior algorithmic generalization. Using a Semiformal DSL-based dual-agent paradigm, we demonstrate that a 1-layer recurrent model can outperform a 12-layer static transformer in out-of-distribution arithmetic tasks while using 12x fewer parameters. Furthermore, we identify the ultimate limits of implicit reasoning capacity through catastrophic interference in algebraic equations, paving the way for Hardware-Software Co-designed explicit reasoning engines.
    </div>

    <h2>1. The SPAK Methodology: The Dual-Agent Paradigm</h2>
    <p>This project demonstrates a systematic approach to GPU kernel engineering and deep learning architecture design using <strong>Semiformal DSL (Domain Specific Language)</strong> as the core medium for semantic communication between AI agents.</p>
    
    <div class="case-description">
        <h3>ğŸ¤– The Dual-Agent Paradigm</h3>
        <p>LLM agents operate in two distinct specialized roles, synchronized through the DSL:</p>
        <ul>
            <li><strong>System Engineer (Architect):</strong> Responsible for high-level design, DSL definition, and defining the "laws of physics" for the model. They bridge the gap between abstract mathematical goals and structural constraints.</li>
            <li><strong>Kernel Engineer (Implementer):</strong> Responsible for low-level GPU kernel implementation using cuTile and conducting rigorous experiments to validate the Architect's design.</li>
        </ul>
    </div>

    <h2>2. The SPAK Progressive Kernel Roadmap</h2>
    <p>Our research evolved through four distinct phases, each building upon hardware insights. All kernels were implemented using the <strong>NVIDIA cuTile Python DSL</strong>, with optimizations guided by the <strong>TileGym reference code</strong>.</p>

    <h3>2.1. MatMul: The Hardware Foundation</h3>
    <p>Optimized basic operation \( C = A \times B \) focusing on <strong>Tiling</strong>, <strong>Shared Memory Swizzling</strong>, and <strong>Pipelining</strong> on RTX5070 Blackwell architectures.</p>

    <h3>2.2. FMHA: Fusing for Bandwidth</h3>
    <p>Minimized HBM traffic by fusing Softmax and Attention into a single kernel, effectively reducing the memory-wall bottleneck.</p>
    <div class="formula">
        \[ \text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \]
    </div>

    <h3>2.3. nanoGPT & LoopLM: Positional Geometric Logic & Temporal Depth</h3>
    <p>Integrated <strong>Rotary Position Embeddings (RoPE)</strong> for translation-invariant logic, and replaced spatial layers with a recurrent loop where state \( h \) evolves \( L \) times through a shared block:</p>
    <div class="formula">
        \[ h_{l+1} = \text{Block}(h_l), \quad (\text{where } inject\_x_0 = \text{False}) \]
    </div>

    <h2>3. LoopLM Experimental Analysis</h2>
    
    <h3>3.1. Experimental Results</h3>
    <p>The following results compare spatial depth against temporal recurrence on Out-of-Distribution (OOD) arithmetic tasks (trained on 1-4 digits, evaluated zero-shot on 5+ digits):</p>

    <table>
        <thead>
            <tr>
                <th>Model Architecture</th>
                <th>1-4d (Train)</th>
                <th>5-6d (OOD)</th>
                <th>8d (OOD)</th>
                <th>Params</th>
                <th>Efficiency</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>GPT-12L (Static)</td><td>100%</td><td>61.90%</td><td>0.00%</td><td>~85M</td><td>1.0x</td></tr>
            <tr><td>LoopLM-12 (Dynamic)</td><td>100%</td><td>80.00%</td><td>0.00%</td><td>~7M</td><td>12.1x</td></tr>
            <tr class="highlight-row"><td>LoopLM-30 (Deep Thinking)</td><td>100%</td><td>95.24%</td><td>2.59%</td><td>~7M</td><td>12.1x</td></tr>
            <tr><td>LoopLM-128e (Efficient)</td><td>100%</td><td>76.19%</td><td>0.00%</td><td>~2M</td><td>42.5x</td></tr>
            <tr><td>LoopLM-12 (Test-Time 24)</td><td>100%</td><td>78.10%</td><td>0.00%</td><td>~7M</td><td>N/A</td></tr>
        </tbody>
    </table>

    <div class="figure">
        <img src="looplm/paper_assets/fig1_generalization_curve.png" alt="">
        <div class="figure-caption"><strong>Figure 1: Generalization Curve.</strong> Illustrates accuracy decay as operand length increases. LoopLM-30 maintains the highest logical integrity, reaching the 8-digit frontier where static baselines completely collapse.</div>
    </div>

    <h3>3.2. Key Discoveries and Scientific Claims</h3>
    
    <div class="insight-box">
        <h4>ğŸ’¡ Claim 1: Recurrence is Depth</h4>
        <p>We proved that temporal recurrence provides superior logical capacity than spatial stacking. LoopLM-12 achieved an 18.1% absolute gain over GPT-12L in OOD tasks while utilizing 12x fewer parameters. By sharing weights across time steps, the model internalizes the algorithm (e.g., Carry propagation) rather than memorizing surface patterns.</p>
    </div>

    <div class="insight-box">
        <h4>ğŸ’¡ Claim 2: The Limits of Inference-Only Test-Time Compute</h4>
        <p>We attempted a zero-shot Test-Time Compute experiment by forcing a 12-loop trained model to run for 24 loops during inference. The accuracy slightly dropped (80.0% &rarr; 78.1%). This highlights the <strong>Dynamical Instability (State Drift)</strong> in recurrent implicit reasoning; unlearned step embeddings act as noise, causing the hidden state to drift away from the correct attractor point.</p>
    </div>

    <div class="insight-box">
        <h4>ğŸ’¡ Claim 3: The Capacity Bottleneck and Catastrophic Interference</h4>
        <p>To test the ultimate limits of the 256-dimensional hidden state, we introduced <strong>Algebraic Equations</strong> (e.g., <code>X+B=C</code>, requiring subtraction). When forced to learn both forward (Addition) and backward (Subtraction) logic simultaneously, both GPT-12L and LoopLM-30 experienced <strong>Catastrophic Interference</strong>, plummeting their previously perfect base addition accuracy down to ~31%. This proves that implicit reasoning has a hard capacity limit when storing multiple mathematical algorithms inside a single vector.</p>
    </div>

    <h2>4. Future Work: The Transition to Explicit Reasoning (CoT)</h2>
    <p>The catastrophic interference observed in Phase 8 serves as the definitive scientific justification for transitioning from Implicit Reasoning (Hidden States) to <strong>Explicit Reasoning (Scratchpad / Chain-of-Thought)</strong>. Instead of compressing the entire algorithmic state into a finite vector, the next generation of SPAK models will offload memory by generating intermediate calculation tokens (e.g., <code>[1+4=5c0...]</code>).</p>
    <p>While Explicit Reasoning inherently increases computational latency due to autoregressive token generation, our custom <strong>FMHA kernels and 1-Layer LoopLM architecture</strong> provide the perfect hardware-software co-designed environment to mitigate this memory-bandwidth bottleneck, promising a highly efficient Turing-complete math agent.</p>

    <h2>5. Conclusion</h2>
    <p>The journey from MatMul to LoopLM demonstrates that GPU kernel engineering is no longer just a matter of low-level optimization, but a <strong>systematic alignment between hardware constraints and architectural intelligence</strong>. By utilizing Semiformal DSLs, we successfully proved the efficiency of temporal depth. The limitations we encountered have illuminated the precise path forward, establishing a robust framework for building the next generation of hardware-aware reasoning engines.</p>

    <hr class="divider">

    <h1>[í•œê¸€ ë²„ì „] ì¬ê·€í˜• ì§€ëŠ¥ì„ ìœ„í•œ GPU ì»¤ë„ì˜ ì ì§„ì  ì§„í™”</h1>
    <div class="authors">SPAK (Systematic Paradigms for AI Kernels) ì—°êµ¬íŒ€</div>

    <div class="abstract">
        <strong>ì´ˆë¡:</strong> ë³¸ ë³´ê³ ì„œëŠ” ê¸°ë³¸ì ì¸ í–‰ë ¬ ì—°ì‚°(MatMul)ì—ì„œ ì‹œì‘í•˜ì—¬ ì¬ê·€í˜• ì–¸ì–´ ëª¨ë¸(LoopLM)ì— ì´ë¥´ê¸°ê¹Œì§€ ê³ ì„±ëŠ¥ GPU ì»¤ë„ì˜ ì ì§„ì ì¸ ì—”ì§€ë‹ˆì–´ë§ ì—¬ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê³µê°„ì  ê¹Šì´(Layer) ëŒ€ì‹  ì‹œê°„ì  ë°˜ë³µ(Loop)ì„ í™œìš©í•˜ì—¬ íƒì›”í•œ ì•Œê³ ë¦¬ì¦˜ ì¼ë°˜í™”ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì¤€ì •í˜• DSL ê¸°ë°˜ì˜ ë“€ì–¼ ì—ì´ì „íŠ¸ íŒ¨ëŸ¬ë‹¤ì„ì„ í†µí•´, 1ê°œ ì¸µì˜ ì¬ê·€ ëª¨ë¸ì´ 12ë°° ì ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ê³ ë„ 12ì¸µì˜ ì •ì  íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì••ë„í•  ìˆ˜ ìˆìŒì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤. ë‚˜ì•„ê°€, ëŒ€ìˆ˜í•™ ë°©ì •ì‹ ì‹¤í—˜ì„ í†µí•´ ì•”ë¬µì  ì¶”ë¡ (Implicit Reasoning)ì˜ í•œê³„ë¥¼ ê·œëª…í•˜ê³  ì°¨ì„¸ëŒ€ í•˜ë“œì›¨ì–´ ì¸ì§€í˜• ëª…ì‹œì  ì¶”ë¡ (Explicit Reasoning) ì—”ì§„ìœ¼ë¡œ ë‚˜ì•„ê°ˆ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.
    </div>

    <h2>1. SPAK ë°©ë²•ë¡ : ë“€ì–¼ ì—ì´ì „íŠ¸ íŒ¨ëŸ¬ë‹¤ì„</h2>
    <p>ë³¸ í”„ë¡œì íŠ¸ëŠ” AI ì—ì´ì „íŠ¸ ê°„ì˜ ì˜ë¯¸ë¡ ì  í†µì‹ ì„ ìœ„í•œ í•µì‹¬ ë§¤ê°œì²´ë¡œì„œ <strong>ì¤€ì •í˜• DSL (Domain Specific Language)</strong>ì„ ì‚¬ìš©í•˜ì—¬ GPU ì»¤ë„ ì—”ì§€ë‹ˆì–´ë§ ë° ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ ì„¤ê³„ì— ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.</p>
    
    <div class="case-description">
        <h3>ğŸ¤– ë“€ì–¼ ì—ì´ì „íŠ¸ íŒ¨ëŸ¬ë‹¤ì„</h3>
        <ul>
            <li><strong>ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´ (Architect):</strong> ê³ ìˆ˜ì¤€ ì„¤ê³„ ë° ë¬¼ë¦¬ ë²•ì¹™ ì •ì˜. ì¶”ìƒì  ëª©í‘œë¥¼ êµ¬ì¡°ì  ì œì•½ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜.</li>
            <li><strong>ì»¤ë„ ì—”ì§€ë‹ˆì–´ (Implementer):</strong> cuTileì„ ì‚¬ìš©í•œ ì €ìˆ˜ì¤€ GPU ì»¤ë„ êµ¬í˜„ ë° ê°€ì„¤ ê²€ì¦ ì‹¤í—˜ ìˆ˜í–‰.</li>
        </ul>
    </div>

    <h2>2. SPAK ì ì§„ì  ì»¤ë„ ë¡œë“œë§µ</h2>
    <p>MatMul(Tiling/Swizzling), FMHA(Kernel Fusion), nanoGPT(RoPE Geometric Logic)ë¥¼ ê±°ì³ LoopLM(Temporal Depth)ìœ¼ë¡œ ì§„í™”í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì»¤ë„ì€ <strong>NVIDIA cuTile Python DSL</strong>ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

    <h2>3. LoopLM ì‹¤í—˜ ë¶„ì„ ë° í•µì‹¬ í†µì°°</h2>
    
    <h3>3.1. ì‹¤í—˜ ê²°ê³¼ ìš”ì•½</h3>
    <p>1~4ìë¦¬ ë§ì…ˆìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ë“¤ì´ ë¯¸í•™ìŠµ ì˜ì—­(5ìë¦¬ ì´ìƒ)ì—ì„œ ë³´ì—¬ì¤€ OOD ì¼ë°˜í™” ì„±ëŠ¥ì…ë‹ˆë‹¤.</p>
    <table>
        <thead>
            <tr>
                <th>ëª¨ë¸ ì•„í‚¤í…ì²˜</th>
                <th>1-4ìë¦¬ (í•™ìŠµ)</th>
                <th>5-6ìë¦¬ (OOD)</th>
                <th>8ìë¦¬ (OOD)</th>
                <th>íŒŒë¼ë¯¸í„°</th>
                <th>íš¨ìœ¨ì„±</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>GPT-12L (Static)</td><td>100%</td><td>61.90%</td><td>0.00%</td><td>~85M</td><td>1.0x</td></tr>
            <tr><td>LoopLM-12 (Dynamic)</td><td>100%</td><td>80.00%</td><td>0.00%</td><td>~7M</td><td>12.1x</td></tr>
            <tr class="highlight-row"><td>LoopLM-30 (Deep Thinking)</td><td>100%</td><td>95.24%</td><td>2.59%</td><td>~7M</td><td>12.1x</td></tr>
            <tr><td>LoopLM-128e (Efficient)</td><td>100%</td><td>76.19%</td><td>0.00%</td><td>~2M</td><td>42.5x</td></tr>
        </tbody>
    </table>

    <div class="figure">
        <img src="looplm/paper_assets/fig1_generalization_curve.png" alt="">
        <div class="figure-caption"><strong>ê·¸ë¦¼ 1: ì¼ë°˜í™” ê³¡ì„ .</strong> ì…ë ¥ ìë¦¿ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ì •í™•ë„ í•˜ë½. ê³µê°„ì„ ìŒ“ì€ GPT-12Lì´ ì¡°ê¸° ë¶•ê´´í•˜ëŠ” ë°˜ë©´, ì‹œê°„ì„ í™œìš©í•œ LoopLM ë³€ì²´ë“¤ì€ í›Œë¥­í•œ ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.</div>
    </div>

    <h3>3.2. ì—”ì§€ë‹ˆì–´ë§ ë‚œì œ ë° í•µì‹¬ í†µì°° (Insights)</h3>
    
    <div class="insight-box">
        <h4>ğŸ’¡ 1. ì¬ê·€ê°€ ê³§ ê¹Šì´ë‹¤ (Recurrence is Depth)</h4>
        <p>ì‹œê°„ì  ë°˜ë³µ(Loop)ì€ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•˜ë¯€ë¡œ, ëª¨ë¸ì´ í‘œë©´ì  íŒ¨í„´ì„ ì•”ê¸°í•˜ì§€ ì•Šê³  'ë°›ì•„ì˜¬ë¦¼(Carry)'ì´ë¼ëŠ” ì§„ì§œ ëŒ€ìˆ˜ì  ì•Œê³ ë¦¬ì¦˜ì„ ì²´í™”í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ê·¸ ê²°ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ 1/12ë¡œ ì¤„ì´ê³ ë„ OOD ì •í™•ë„ë¥¼ 18%p ì´ìƒ ìƒìŠ¹ì‹œì¼°ìŠµë‹ˆë‹¤.</p>
    </div>

    <div class="insight-box">
        <h4>ğŸ’¡ 2. ìƒíƒœ í‘œë¥˜ (State Drift)ì™€ ì¶”ë¡  í™•ì¥(Test-Time Compute)ì˜ í•œê³„</h4>
        <p>12ë£¨í”„ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì¶”ë¡  ì‹œì—ë§Œ 24ë£¨í”„ë¡œ ê°•ì œ í™•ì¥í•œ ê²°ê³¼, ì„±ëŠ¥ì€ ìƒìŠ¹í•˜ì§€ ì•Šê³  ì˜¤íˆë ¤ í•˜ë½(80% &rarr; 78.1%)í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” í•™ìŠµë˜ì§€ ì•Šì€ ë£¨í”„ êµ¬ê°„ì—ì„œ ë°œìƒí•˜ëŠ” ë…¸ì´ì¦ˆê°€ ëª¨ë¸ì˜ ì€ë‹‰ ìƒíƒœ(Hidden State)ë¥¼ ì •ë‹µ ê¶¤ì ì—ì„œ ì´íƒˆì‹œí‚¤ëŠ” <strong>ë™ì—­í•™ì  ë¶ˆì•ˆì •ì„±</strong>ì„ ì¦ëª…í•©ë‹ˆë‹¤.</p>
    </div>

    <div class="insight-box">
        <h4>ğŸ’¡ 3. ìš©ëŸ‰ì˜ ë³‘ëª©ê³¼ íŒŒêµ­ì  ê°„ì„­ (Catastrophic Interference)</h4>
        <p>ì€ë‹‰ ìƒíƒœ(256ì°¨ì›)ì˜ ë¬¼ë¦¬ì  í•œê³„ë¥¼ ì‹œí—˜í•˜ê¸° ìœ„í•´, ë§ì…ˆê³¼ ëº„ì…ˆ(ì—­ì—°ì‚°)ì„ ëª¨ë‘ ìœ ì¶”í•´ì•¼ í•˜ëŠ” ëŒ€ìˆ˜í•™ ë°©ì •ì‹(<code>X+B=C</code>) ë°ì´í„°ë¥¼ íˆ¬ì…í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ 12ì¸µ GPTì™€ 30ë£¨í”„ LoopLM ëª¨ë‘ 100%ì˜€ë˜ ê¸°ë³¸ ë§ì…ˆ ëŠ¥ë ¥ì´ 31%ë¡œ ë¶•ê´´í•˜ëŠ” <strong>íŒŒêµ­ì  ê°„ì„­</strong>ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¨ì¼ ë²¡í„° ì•ˆì— ë³µìˆ˜ì˜ ì•Œê³ ë¦¬ì¦˜ ìƒíƒœë¥¼ êµ¬ê²¨ ë„£ëŠ” 'ì•”ë¬µì  ì¶”ë¡ 'ì˜ ê·¼ë³¸ì  í•œê³„ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.</p>
    </div>

    <h2>4. í–¥í›„ ê³¼ì œ: ëª…ì‹œì  ì¶”ë¡ (Scratchpad)ìœ¼ë¡œì˜ ì „í™˜</h2>
    <p>ë°©ì •ì‹ ì‹¤í—˜ì—ì„œ í™•ì¸ëœ 'íŒŒêµ­ì  ê°„ì„­'ì€ ëª¨ë¸ì—ê²Œ <strong>ëª…ì‹œì  ì¶”ë¡ (Explicit Reasoning / Chain-of-Thought)</strong>ì„ í—ˆìš©í•´ì•¼ í•  ì™„ë²½í•œ ê³¼í•™ì  ëª…ë¶„ì…ë‹ˆë‹¤. ì¤‘ê°„ ê³„ì‚° ê³¼ì •ì„ ì§ì ‘ í† í°ìœ¼ë¡œ ì „ê°œí•˜ëŠ” Scratchpad ë°©ì‹ì„ ë„ì…í•˜ì—¬ ì •ë³´ ë³‘ëª©ì„ í•´ì†Œí•  ê³„íšì…ë‹ˆë‹¤.</p>
    <p>ì´ë•Œ ë°œìƒí•˜ëŠ” ì‹¬ê°í•œ í† í° ìƒì„± ì§€ì—°(Latency) í˜„ìƒì€ ìš°ë¦¬ê°€ ë°‘ë°”ë‹¥ë¶€í„° êµ¬ì¶•í•œ <strong>1-Layer LoopLM êµ¬ì¡°ì™€ FMHA ì»¤ë„</strong>ì„ í†µí•´ ê·¹ë³µí•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ê°€ì¥ íš¨ìœ¨ì ì¸ í•˜ë“œì›¨ì–´-ì†Œí”„íŠ¸ì›¨ì–´ ê³µë™ ì„¤ê³„(Co-design) ìˆ˜í•™ ì—ì´ì „íŠ¸ì˜ íƒ„ìƒì„ ì˜ˆê³ í•©ë‹ˆë‹¤.</p>

    <h2>5. ê²°ë¡ </h2>
    <p>MatMulì—ì„œ LoopLMì— ì´ë¥´ëŠ” ì—¬ì •ì€ GPU ì»¤ë„ ì—”ì§€ë‹ˆì–´ë§ì´ ë‹¨ìˆœíˆ ì €ìˆ˜ì¤€ ìµœì í™”ì˜ ë¬¸ì œê°€ ì•„ë‹ˆë¼, <strong>í•˜ë“œì›¨ì–´ ì œì•½ ì¡°ê±´ê³¼ ì•„í‚¤í…ì²˜ì  ì§€ëŠ¥ ì‚¬ì´ì˜ ì²´ê³„ì ì¸ ì •ë ¬</strong>ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì˜ SPAK íŒ¨ëŸ¬ë‹¤ì„ì€ í•œê³„ì ë§ˆì €ë„ ë‹¤ìŒ í˜ì‹ ì„ ìœ„í•œ ë‚˜ì¹¨ë°˜ìœ¼ë¡œ ì‚¼ì•„, ì°¨ì„¸ëŒ€ í•˜ë“œì›¨ì–´ ì¸ì§€í˜• ì¶”ë¡  ì—”ì§„ì„ ìœ„í•œ ê²¬ê³ í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>

    <hr class="divider">
    
    <h2>Appendix: Semiformal DSL (LoopLM_System_v3.dsl)</h2>
    <pre class="appendix-code">
---
title: "LoopLM System v3 â€“ Algorithmic Generalization & Systematic Engineering"
source: "SPAK Phase 3-4 Research + Blackwell Optimization"
extraction-date: 2026-02-26
tags: [LoopLM, Grokking, Wait-to-Think, OOD, Systematic_Experimentation, Blackwell_V2]
status: "active"
---

system LoopLM_System_v3 {

  objective Algorithmic_Emergence {
      target: "Achieve >70% Accuracy on 12-digit Addition (Zero-shot)"
      mechanism: "Transition from Memorization to Algorithmic Logic (Grokking)"
      hardware: "RTX 5070 (Blackwell) Persistent Optimization"
  }

  knowledge {
      fact algorithmic_grokking_emergence {
          description: "LoopLM-30 (Deep) achieved 100% on bridge data and 2.6% on 8-digit OOD."
          evidence: "Phase 5 re-evaluation after Format Parity Fix."
      }
      fact catastrophic_interference_in_algebra {
          description: "Introducing bidirectional logic (X+B=C) caused base addition accuracy to collapse to 31%."
          evidence: "Phase 8 Algebra experiments (Both GPT-12L and LoopLM-30 collapsed equally)."
          conclusion: "Implicit reasoning capacity is strictly bounded. Must transition to Explicit Scratchpad/CoT."
      }
  }
}
    </pre>
</div>
</body>
</html>