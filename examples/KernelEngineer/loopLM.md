# loopLM: 잠재적 추론(Latent Reasoning)을 위한 반복형 언어 모델 설계

**loopLM**은 고정된 깊이(Depth)의 트랜스포머를 넘어, 동일한 디코더 블록을 여러 번 반복(Loop)하여 계산 깊이를 "시간" 차원으로 확장함으로써 **잠재적 추론 능력**을 확보하는 차세대 아키텍처입니다. SPAK의 FMHA, MicroGPT, NanoGPT 엔지니어링을 통해 축적된 지식은 loopLM을 실현하는 핵심 기반이 됩니다.

---

### 1. 설계 비전: 공간(Space)에서 시간(Time)으로의 확장

기존 모델이 층(Layer)을 쌓아 파라미터를 늘리는 데 집중했다면, loopLM은 **동일한 파라미터를 반복 재사용**하여 추론의 깊이를 더합니다.

*   **재귀적 정교화 (Recursive Refinement)**: 입력을 한 번에 처리하지 않고, 잠재 공간(Latent Space)에서 여러 번 순환시키며 표현을 정교화합니다.
*   **가변적 연산량 (Adaptive Compute)**: 쉬운 문제는 적은 반복으로, 복잡한 추론이 필요한 문제는 더 많은 반복을 할당하여 효율성을 극대화합니다.
*   **지식의 고밀도화**: NanoGPT에서 증명된 고성능 커널들을 반복 구조에 통합하여, 적은 파라미터로도 거대 모델에 필적하는 추론 성능을 목표로 합니다.

---

### 2. SPAK 엔지니어링 지식의 전이 (Knowledge Transfer)

지금까지 축적된 지식은 loopLM의 물리적 구현과 수치적 안정성을 보장합니다.

| 축적된 지식 (Asset) | loopLM 적용 시나리오 | 기대 효과 |
| :--- | :--- | :--- |
| **Blackwell TMA Laws ($V_{Lat}=5$)** | 반복되는 블록 내에서 가중치(Weights)의 **지속성(Persistence)** 활용 | HBM 대역폭 낭비 최소화 및 레이턴시 은폐 |
| **Stability Floor ($-1e20$)** | 수십 번의 반복 루프에서 발생할 수 있는 **수치적 발산 방지** | 깊은 재귀 구조에서도 안정적인 학습 및 추론 |
| **Pow2-Masking LayerNorm** | 표준 임베딩 차원(384/768)에서의 고속 정규화 유지 | 반복 마다 발생하는 정규화 오버헤드 최소화 |
| **GQA/Causal Fusion** | 루프 간 KV 캐시 관리 및 어텐션 연산 가속 | 반복적인 컨텍스트 참조의 효율성 극대화 |

---

### 3. loopLM을 위한 핵심 엔지니어링 전략

#### 3.1. 지속적 가중치 캐싱 (Persistent Weight Caching)
loopLM은 동일한 가중치를 반복해서 사용합니다. Blackwell 아키텍처의 TMA를 활용하여, 루프가 시작될 때 가중치를 L2 캐시나 공유 메모리에 **고정(Pinning)**하고, 전체 반복 동안 재로드 없이 사용하는 전략을 취합니다. 이는 기존 NanoGPT 대비 메모리 액세스 비용을 획기적으로 낮춥니다.

#### 3.2. 루프 간 파이프라이닝 (Inter-Loop Pipelining)
$n$번째 루프의 연산(MMA)이 진행되는 동안, $n+1$번째 루프에서 필요한 데이터를 미리 로드하는 **이중 버퍼링(Double Buffering)** 기술을 FMHA 최적화 경험을 바탕으로 구현합니다.

#### 3.3. 적응형 정지 규칙 (Adaptive Stopping Rule)
SPAK의 **Outer Loop (Strategic Agent)**를 활용하여, 잠재 공간의 엔트로피나 변화량을 모니터링하고 최적의 반복 횟수를 결정하는 '정지 정책(Stop Policy)'을 DSL 수준에서 진화시킵니다.

---

### 4. 로드맵: 원자에서 지능으로

1.  **Step 1 (Atom)**: NanoGPT의 디코더 블록을 단일 루프 커널로 캡슐화 (loopLM_v1.dsl).
2.  **Step 2 (Molecule)**: 고정 반복 횟수(Fixed Loops) 환경에서 수렴 안정성 및 Blackwell TMA 캐싱 효율 검증.
3.  **Step 3 (Organism)**: "Reasoning with Latent Thoughts" 논문의 기법을 적용하여, 잠재 공간에서의 사고(Thinking) 과정을 추적하고 성능 측정.

### 💎 결론: 추론하는 시스템으로의 진화

loopLM은 단순한 모델이 아니라, 우리가 지금까지 쌓아온 **"하드웨어 최적화 지식"**과 **"시스템 아키텍처"**가 결합되어 탄생하는 **지능적 실행체**입니다. NanoGPT가 성능의 한계를 보여주었다면, loopLM은 그 성능을 바탕으로 모델이 어떻게 "생각"할 수 있는지를 보여주는 첫 번째 사례가 될 것입니다.
