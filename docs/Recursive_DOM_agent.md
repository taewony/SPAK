ë„¤, **Windows PC í™˜ê²½**ì—ì„œ **Ollamaì˜ Tool Calling(Function Calling)** ê¸°ëŠ¥ì„ í™œìš©í•˜ë©´ ì´ ì•„ì´ë””ì–´ë¥¼ ì™„ë²½í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ìµœì‹  Llama 3.1ì´ë‚˜ Llama 3.2 ëª¨ë¸ì€ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì´ ë§¤ìš° ë›°ì–´ë‚©ë‹ˆë‹¤.

í•™ìƒë“¤ì„ ìœ„í•œ **"Project: Recursive DOM Agent (RDA)"** ê°œë°œ ê°œìš”ì„œ(Outline)ë¥¼ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤. ì´ ë¬¸ì„œë¥¼ ì»¤ë¦¬í˜ëŸ¼ì˜ ê¸°ì´ˆ ìë£Œë¡œ í™œìš©í•˜ì„¸ìš”.

---

# **ğŸ“‚ Project: Recursive DOM Agent (RDA) on Windows**

## **1\. í”„ë¡œì íŠ¸ ê°œìš” (Project Overview)**

* **ëª©í‘œ:** LLMì˜ Context Window í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë¹„ì •í˜• í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ **DOM(Document Object Model)** êµ¬ì¡°ë¡œ ë³€í™˜í•˜ê³ , LLMì´ **CSS Selector**ë¥¼ ë„êµ¬(Tool)ë¡œ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ëŠ¥ë™ì ìœ¼ë¡œ íƒìƒ‰ ë° ì¬ê·€ì (Recursive)ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ê°œë°œí•œë‹¤.  
* **í•µì‹¬ ê°œë…:**  
  * **Context as a Database:** í…ìŠ¤íŠ¸ë¥¼ ì½ëŠ” ëŒ€ìƒì´ ì•„ë‹Œ 'ì¡°íšŒ(Query)'ì˜ ëŒ€ìƒìœ¼ë¡œ ì·¨ê¸‰.  
  * **Tool Use:** LLMì´ ìŠ¤ìŠ¤ë¡œ Python í•¨ìˆ˜(select, map\_reduce)ë¥¼ í˜¸ì¶œ.  
  * **Recursive Processing:** í° ë¬¸ì œë¥¼ ì‘ì€ ë‹¨ìœ„(Node)ë¡œ ìª¼ê°œì–´ í•˜ìœ„ ì—ì´ì „íŠ¸ì—ê²Œ ìœ„ì„.

## **2\. ê°œë°œ í™˜ê²½ (Environment Setup)**

í•™ìƒë“¤ì´ ë³´ìœ í•œ Windows PC(RTX 4070)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.

* **OS:** Windows 10/11 (PowerShell ë˜ëŠ” WSL2 ê¶Œì¥)  
* **Language:** Python 3.10 ì´ìƒ  
* **Core Engine:** [Ollama for Windows](https://ollama.com/download/windows)  
* **Target Model:**  
  * llama3.1:8b (Main Controller \- ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì´ ì¢‹ìŒ)  
  * llama3.2:3b (Sub-Worker \- ë‹¨ìˆœ ìš”ì•½ ë“± ë¹ ë¥¸ ì²˜ë¦¬ì— ì í•©)  
* **Key Libraries:**  
  * ollama: LLM í†µì‹  ë° ë„êµ¬ í˜¸ì¶œ  
  * beautifulsoup4 & lxml: DOM íŒŒì‹± ë° CSS Selector ì—”ì§„  
  * rich: í„°ë¯¸ë„ UI ì‹œê°í™” (Tree êµ¬ì¡° ì¶œë ¥ìš©)

---

## **3\. ì£¼ì°¨ë³„ ê°œë°œ ë‹¨ê³„ (Development Roadmap)**

### **Phase 1: ê¸°ë°˜ í™˜ê²½ êµ¬ì¶• (Infrastructure)**

Ollamaë¥¼ ì„¤ì¹˜í•˜ê³  Pythonì—ì„œ ì œì–´í•˜ëŠ” ê¸°ì´ˆ ë‹¨ê³„ì…ë‹ˆë‹¤.

1. **Ollama Setup:** Windowsìš© Ollama ì„¤ì¹˜ ë° GPU ê°€ì† í™•ì¸ (ollama run llama3.1 ì‹¤í–‰).  
2. **API Binding:** Python import ollamaë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸.  
3. **Data Preparation:** ê¸´ Markdown ë¬¸ì„œ(ì˜ˆ: ê°•ì˜ë¡, ë§¤ë‰´ì–¼)ë¥¼ ì¤€ë¹„í•˜ê³ , ì´ë¥¼ Python ìŠ¤í¬ë¦½íŠ¸ë¡œ **HTML/XML í¬ë§·ìœ¼ë¡œ ë³€í™˜**í•˜ì—¬ ì €ì¥í•˜ëŠ” ì „ì²˜ë¦¬ê¸°(Preprocessor) ì‘ì„±.

### **Phase 2: ê°€ìƒ í™˜ê²½(Environment) í´ë˜ìŠ¤ êµ¬í˜„**

LLMì´ ì ‘ì†í•  "ë°ì´í„°ë² ì´ìŠ¤(DOM)"ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤. LLM ì—†ì´ ìˆœìˆ˜ Python ë¡œì§ìœ¼ë¡œ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤.

1. **DOM Loader:** BeautifulSoupì„ ì´ìš©í•´ XML ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ.  
2. **Tools Implementation:**  
   * get\_structure(): ë¬¸ì„œì˜ ëª©ì°¨(ID, íƒœê·¸, Title)ë§Œ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜ (í† í° ì ˆì•½ìš©).  
   * read\_node(selector): íŠ¹ì • CSS Selectorì— í•´ë‹¹í•˜ëŠ” ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜.  
   * *Unit Test:* êµìˆ˜ê°€ ì œê³µí•œ selectorë¥¼ ì…ë ¥í–ˆì„ ë•Œ ì •í™•í•œ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ëŠ”ì§€ í…ŒìŠ¤íŠ¸.

### **Phase 3: Ollama Tool Binding (The Brain)**

Llama 3.1 ëª¨ë¸ì—ê²Œ Phase 2ì—ì„œ ë§Œë“  íŒŒì´ì¬ í•¨ìˆ˜ë“¤ì„ "ë„êµ¬"ë¡œ ì¥ì–´ì£¼ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.

1. **Tool Definition:** get\_structure, read\_node í•¨ìˆ˜ë¥¼ Ollamaê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” JSON Schema í˜•íƒœë¡œ ì •ì˜.  
2. **Chat Loop (REPL):**  
   * ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ \-\> Ollamaì—ê²Œ ì „ë‹¬ (with Tools).  
   * Ollamaê°€ ë„êµ¬ í˜¸ì¶œ ìš”ì²­(tool\_calls) \-\> Pythonì´ í•´ë‹¹ í•¨ìˆ˜ ì‹¤í–‰.  
   * í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ \-\> ë‹¤ì‹œ Ollamaì—ê²Œ ì „ë‹¬ (Role: tool).  
   * Ollamaê°€ ìµœì¢… ë‹µë³€ ìƒì„±.

### **Phase 4: ì¬ê·€ì (Recursive) ê¸°ëŠ¥ êµ¬í˜„ (The Magic)**

ë‹¨ìˆœ ì¡°íšŒë¥¼ ë„˜ì–´, ì˜ìƒì—ì„œ ë³¸ RLM(Recursive LM) ê°œë…ì„ ì ìš©í•©ë‹ˆë‹¤.

1. **map\_reduce ë„êµ¬ ì¶”ê°€:**  
   * ì…ë ¥: selector (ì˜ˆ: section.case\_study), query (ì˜ˆ: "ì´ ì‚¬ë¡€ì˜ í•µì‹¬ ì›ì¸ ë¶„ì„í•´ì¤˜").  
   * ë™ì‘:  
     1. Selectorë¡œ $N$ê°œì˜ ë…¸ë“œë¥¼ ì°¾ìŒ.  
     2. for ë£¨í”„ë¥¼ ëŒë©° ê° ë…¸ë“œ ë‚´ìš©ì— ëŒ€í•´ \*\*ìƒˆë¡œìš´ ollama.chat ì„¸ì…˜(Sub-Agent)\*\*ì„ ìƒì„±í•˜ì—¬ ì§ˆë¬¸.  
     3. $N$ê°œì˜ ë‹µë³€ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì„œ ë°˜í™˜.  
2. **Controller Logic:** ë©”ì¸ LLMì´ "ì „ì²´ ì±•í„° ìš”ì•½" ìš”ì²­ì„ ë°›ìœ¼ë©´, ìŠ¤ìŠ¤ë¡œ map\_reduce ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ìœ ë„.

### **Phase 5: ë°ëª¨ ë° ì‹œê°í™” (Visualization)**

1. **CLI Dashboard:** rich ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬, í˜„ì¬ LLMì´ DOM íŠ¸ë¦¬ì˜ ì–´ëŠ ë¶€ë¶„ì„ ë³´ê³  ìˆëŠ”ì§€, ì–´ë–¤ í•˜ìœ„ ì—ì´ì „íŠ¸ê°€ ëŒê³  ìˆëŠ”ì§€ í„°ë¯¸ë„ì— ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ.  
2. **Final Test:** "ì „ì²´ ë§¤ë‰´ì–¼ì—ì„œ 'ë³´ì•ˆ'ê³¼ ê´€ë ¨ëœ ë‚´ìš©ë§Œ ì°¾ì•„ì„œ, ê° í•­ëª©ë³„ ì¡°ì¹˜ ì‚¬í•­ì„ í‘œë¡œ ë§Œë“¤ì–´ì¤˜"ì™€ ê°™ì€ ë³µí•© ì§ˆì˜ ìˆ˜í–‰.

---

## **4\. í•µì‹¬ ì½”ë“œ êµ¬ì¡° ì˜ˆì‹œ (Python Draft)**

í•™ìƒë“¤ì—ê²Œ ì œê³µí•  ìˆ˜ ìˆëŠ” **Starter Code**ì˜ ê³¨ê²©ì…ë‹ˆë‹¤.

Python

import ollama  
from bs4 import BeautifulSoup  
import json

\# 1\. Environment (DOM Manager)  
class DocumentEnv:  
    def \_\_init\_\_(self, xml\_content):  
        self.soup \= BeautifulSoup(xml\_content, 'xml')  
      
    def get\_structure(self):  
        """ë¬¸ì„œì˜ ë¼ˆëŒ€(IDì™€ Title)ë§Œ ë°˜í™˜"""  
        \# (êµ¬í˜„ ìƒëµ: ë³¸ë¬¸ì„ ì œì™¸í•œ íƒœê·¸ êµ¬ì¡°ë§Œ ë¬¸ìì—´ë¡œ ë¦¬í„´)  
        pass

    def read\_content(self, selector):  
        """íŠ¹ì • ë…¸ë“œì˜ ë‚´ìš©ì„ ì¡°íšŒ"""  
        selected \= self.soup.select(selector)  
        return "\\n".join(\[tag.get\_text() for tag in selected\])

    def map\_reduce(self, selector, sub\_query):  
        """\[Recursive\] ê° ë…¸ë“œì— ëŒ€í•´ í•˜ìœ„ ì—ì´ì „íŠ¸ ì‹¤í–‰"""  
        results \= \[\]  
        targets \= self.soup.select(selector)  
          
        print(f"ğŸ”„ Spawning {len(targets)} sub-agents...")  
        for target in targets:  
            \# í•˜ìœ„ ì—ì´ì „íŠ¸ëŠ” ê°€ë²¼ìš´ ëª¨ë¸(llama3.2) ì‚¬ìš© ê°€ëŠ¥  
            response \= ollama.chat(  
                model='llama3.2',  
                messages=\[  
                    {'role': 'system', 'content': 'ë¶„ì„ê°€ëŠ” ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë§Œ ë³´ê³  ë‹µí•©ë‹ˆë‹¤.'},  
                    {'role': 'user', 'content': f"Context: {target.get\_text()}\\n\\nTask: {sub\_query}"}  
                \]  
            )  
            results.append(response\['message'\]\['content'\])  
        return json.dumps(results)

\# 2\. Tool Definitions for Ollama  
my\_tools \= \[  
    {  
        'type': 'function',  
        'function': {  
            'name': 'get\_structure',  
            'description': 'ë¬¸ì„œì˜ ì „ì²´ ëª©ì°¨ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. íƒìƒ‰ ì „ì— ë°˜ë“œì‹œ ë¨¼ì € í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.',  
            'parameters': {'type': 'object', 'properties': {}}  
        }  
    },  
    {  
        'type': 'function',  
        'function': {  
            'name': 'read\_content',  
            'description': 'CSS Selectorë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.',  
            'parameters': {  
                'type': 'object',  
                'properties': {  
                    'selector': {'type': 'string', 'description': 'CSS Selector (ì˜ˆ: chapter\#1 \> section)'}  
                },  
                'required': \['selector'\]  
            }  
        }  
    },  
    {  
        'type': 'function',  
        'function': {  
            'name': 'map\_reduce',  
            'description': 'ë°˜ë³µì ì¸ ìš”ì†Œë“¤(ì˜ˆ: ëª¨ë“  ì„¹ì…˜)ì— ëŒ€í•´ ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëª¨ìë‹ˆë‹¤.',  
            'parameters': {  
                'type': 'object',  
                'properties': {  
                    'selector': {'type': 'string', 'description': 'ë°˜ë³µí•  ëŒ€ìƒì˜ CSS Selector'},  
                    'sub\_query': {'type': 'string', 'description': 'ê° ëŒ€ìƒì—ê²Œ ìˆ˜í–‰í•  ì§€ì‹œì‚¬í•­'}  
                },  
                'required': \['selector', 'sub\_query'\]  
            }  
        }  
    }  
\]

\# 3\. Main REPL Loop (Simplified)  
def run\_agent(user\_query, env):  
    messages \= \[{'role': 'user', 'content': user\_query}\]  
      
    while True:  
        \# LLMì—ê²Œ ì§ˆë¬¸ \+ ë„êµ¬ ëª©ë¡ ì „ë‹¬  
        response \= ollama.chat(model='llama3.1', messages=messages, tools=my\_tools)  
        msg \= response\['message'\]  
          
        \# ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì¢…ë£Œ  
        if not msg.get('tool\_calls'):  
            print(f"ğŸ¤– Agent: {msg\['content'\]}")  
            break  
              
        \# ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬  
        messages.append(msg) \# ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€  
        for tool in msg\['tool\_calls'\]:  
            fn\_name \= tool\['function'\]\['name'\]  
            args \= tool\['function'\]\['arguments'\]  
            print(f"ğŸ› ï¸ Tool Call: {fn\_name}({args})")  
              
            \# ì‹¤ì œ íŒŒì´ì¬ í•¨ìˆ˜ ì‹¤í–‰  
            if fn\_name \== 'get\_structure':  
                result \= env.get\_structure()  
            elif fn\_name \== 'read\_content':  
                result \= env.read\_content(args\['selector'\])  
            elif fn\_name \== 'map\_reduce':  
                result \= env.map\_reduce(args\['selector'\], args\['sub\_query'\])  
              
            \# ê²°ê³¼ ë°˜í™˜  
            messages.append({'role': 'tool', 'content': str(result)})

\# ì‹¤í–‰ ì˜ˆì‹œ  
\# env \= DocumentEnv(xml\_data)  
\# run\_agent("ì±•í„° 1ì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜", env)

---

## **5\. ê¸°ëŒ€ íš¨ê³¼ ë° í‰ê°€ í¬ì¸íŠ¸**

* **Engineering:** ë‹¨ìˆœíˆ í”„ë¡¬í”„íŠ¸ë§Œ ì¹˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, LLMì„ ì‹œìŠ¤í…œì˜ ëª¨ë“ˆ(í•¨ìˆ˜)ë¡œ ì·¨ê¸‰í•˜ëŠ” ì‚¬ê³ ë°©ì‹ì„ ë°°ì–‘.  
* **Optimization:** llama3.1:8bì™€ llama3.2:3bë¥¼ ì ì¬ì ì†Œì— ì„ì–´ ì“°ëŠ”(Orchestrator-Worker íŒ¨í„´) ìµœì í™” ê²½í—˜.  
* **Interpretability:** LLMì´ ì™œ ê·¸ëŸ° ë‹µì„ ëƒˆëŠ”ì§€, ì–´ë–¤ Toolì„ í˜¸ì¶œí–ˆê³  ì–´ë–¤ ë°ì´í„°ë¥¼ ì°¸ì¡°í–ˆëŠ”ì§€ ë¡œê·¸(Tool Call)ë¥¼ í†µí•´ ëª…í™•íˆ ë””ë²„ê¹… ê°€ëŠ¥.

ì´ í”„ë¡œì íŠ¸ëŠ” 4070 PC í•œ ëŒ€ë§Œìœ¼ë¡œë„ ë¡œì»¬ì—ì„œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ëª¨ì‚¬í•  ìˆ˜ ìˆëŠ” í›Œë¥­í•œ ì‹¤ìŠµì´ ë  ê²ƒì…ë‹ˆë‹¤.

ì•„ì£¼ ì¢‹ì€ ë¬¸ì œ ì„¤ì •ì´ì—ìš”. ì§€ê¸ˆ ì§ˆë¬¸ì€ \*\*â€œRecursive LM ë…¼ë¬¸ì—ì„œ ë§í•˜ëŠ” í™˜ê²½ E \+ context Cë¥¼, DOM Tree \+ CSS selectorì²˜ëŸ¼ êµ¬ì¡°í™”í•´ì„œ, REPL ê¸°ë°˜ìœ¼ë¡œ ëˆ„ì  ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œì„ ì–´ë–»ê²Œ êµ¬í˜„í•  ê²ƒì¸ê°€?â€\*\*ì´ê³ ,  
\*\*RTX 4070 / L40S \+ Ollama \+ ì†Œí˜• LLaMA(3Bê¸‰)\*\*ì„ ì „ì œë¡œ í•œ **êµìœ¡ìš© AI ì—”ì§€ë‹ˆì–´ë§ ì•„í‚¤í…ì²˜**ë¥¼ ë¬»ê³  ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ì—ì„œëŠ” **ê°œë…ì  ëŒ€ì‘ â†’ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ â†’ ë°ì´í„° êµ¬ì¡° â†’ REPL/Selector ì„¤ê³„ â†’ Ollama ì—°ë™ â†’ ìˆ˜ì—…ìš© í™•ì¥ í¬ì¸íŠ¸** ìˆœì„œë¡œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.

---

## **1\. ê°œë…ì  ëŒ€ì‘ (DOM/CSS â†” Recursive LM)**

ë¨¼ì € ë¹„ìœ ë¥¼ ëª…í™•íˆ ì •ë¦¬í•´ë³´ë©´ í•™ìƒë“¤ì—ê²Œë„ ì„¤ëª…ì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤.

| Web ê°œë… | Recursive LM ê°œë… |
| ----- | ----- |
| DOM Tree | Context Tree (C-Tree) |
| DOM Node | Context Node (cáµ¢) |
| CSS Selector | Context Selector DSL |
| querySelector | context.select() |
| JS ì‹¤í–‰ í™˜ê²½ | Python REPL Environment E |
| innerHTML ë³€ê²½ | context node transform / annotate |
| Virtual DOM diff | Context versioning / snapshot |

ì¦‰:

**Context Cë¥¼ â€œê¸´ ë¬¸ìì—´â€ë¡œ ì·¨ê¸‰í•˜ì§€ ì•Šê³ ,**  
**êµ¬ì¡°ì Â·ê³„ì¸µì Â·ì°¸ì¡° ê°€ëŠ¥í•œ Treeë¡œ ì·¨ê¸‰í•œë‹¤**  
â†’ ì´ê²ƒì´ Recursive LMì˜ í•µì‹¬ êµ¬í˜„ í¬ì¸íŠ¸

---

## **2\. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (êµìœ¡ìš© í˜„ì‹¤ ë²„ì „)**

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
â”‚  Student (REPL / UI)     â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
             â–¼  
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
â”‚ Python REPL Environment  â”‚  â† E  
â”‚  \- context\_tree          â”‚  
â”‚  \- results\_store         â”‚  
â”‚  \- selector DSL          â”‚  
â”‚  \- call\_rlm()            â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
             â–¼  
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
â”‚  Local LLM Backend       â”‚  
â”‚  (Ollama \+ LLaMA 3B)     â”‚  
â”‚                          â”‚  
â”‚  M(q, C\_selected)        â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

í•µì‹¬ì€:

* **Python REPLì´ â€œEnvironment Eâ€**  
* **ContextëŠ” Treeë¡œ ë©”ëª¨ë¦¬ì— ìƒì£¼**  
* **LLMì€ ë„êµ¬ì²˜ëŸ¼ í˜¸ì¶œ**  
* **Recursive callì€ Pythonì—ì„œ spawn**

---

## **3\. Context Tree ì„¤ê³„ (DOM-like)**

### **3.1 ê¸°ë³¸ Context Node**

from dataclasses import dataclass, field  
from typing import List, Dict, Any

@dataclass  
class ContextNode:  
    id: str  
    type: str                  \# e.g. "section", "paragraph", "claim"  
    text: str  
    children: List\["ContextNode"\] \= field(default\_factory=list)  
    meta: Dict\[str, Any\] \= field(default\_factory=dict)

ì˜ˆì‹œ íŠ¸ë¦¬:

root  
 â”œâ”€â”€ c1 (Introduction)  
 â”‚    â”œâ”€â”€ c1.1 (Motivation)  
 â”‚    â””â”€â”€ c1.2 (Problem Statement)  
 â”œâ”€â”€ c2 (Method)  
 â”‚    â”œâ”€â”€ c2.1 (Recursive Call)  
 â”‚    â””â”€â”€ c2.2 (Environment E)  
 â””â”€â”€ c3 (Experiments)

ğŸ‘‰ ë…¼ë¬¸, ì½”ë“œ, ë¡œê·¸, ëŒ€í™” ê¸°ë¡ ëª¨ë‘ ë™ì¼ êµ¬ì¡°ë¡œ ì €ì¥ ê°€ëŠ¥

---

## **4\. CSS-like Context Selector DSL**

### **4.1 ìµœì†Œí•œì˜ Selector ë¬¸ë²• (êµìœ¡ìš©)**

\#id  
type  
type \> type  
type\[type=section\]

### **4.2 Python êµ¬í˜„ ì˜ˆì‹œ**

class ContextTree:  
    def \_\_init\_\_(self, root: ContextNode):  
        self.root \= root

    def select(self, selector: str) \-\> List\[ContextNode\]:  
        \# ì•„ì£¼ ë‹¨ìˆœí•œ êµ¬í˜„ (ìˆ˜ì—…ìš©)  
        if selector.startswith("\#"):  
            return self.\_find\_by\_id(self.root, selector\[1:\])  
        else:  
            return self.\_find\_by\_type(self.root, selector)

    def \_find\_by\_id(self, node, id\_):  
        if node.id \== id\_:  
            return \[node\]  
        result \= \[\]  
        for c in node.children:  
            result.extend(self.\_find\_by\_id(c, id\_))  
        return result

    def \_find\_by\_type(self, node, type\_):  
        result \= \[\]  
        if node.type \== type\_:  
            result.append(node)  
        for c in node.children:  
            result.extend(self.\_find\_by\_type(c, type\_))  
        return result

í•™ìƒ ê³¼ì œ:

* `section > paragraph`  
* `paragraph[meta.score > 0.7]`  
* XPath-like selector í™•ì¥

---

## **5\. RLMM(q, C) êµ¬í˜„ êµ¬ì¡°**

### **5.1 Environment E (Python REPL)**

class RLMEnvironment:  
    def \_\_init\_\_(self, context\_tree, llm):  
        self.context\_tree \= context\_tree  
        self.llm \= llm  
        self.memory \= {}

    def call(self, query, selector):  
        nodes \= self.context\_tree.select(selector)  
        context\_text \= "\\n".join(n.text for n in nodes)

        response \= self.llm.generate(query, context\_text)  
        return response

---

## **6\. Recursive Call (ë…¼ë¬¸ì˜ í•µì‹¬)**

### **6.1 Sub-RLM Spawn**

def recursive\_call(env, query, selector):  
    \# 1\. select sub-context  
    nodes \= env.context\_tree.select(selector)

    \# 2\. transform context (optional)  
    sub\_context \= ContextTree(  
        root=ContextNode(  
            id="subroot",  
            type="subcontext",  
            text="",  
            children=nodes  
        )  
    )

    \# 3\. new isolated environment  
    sub\_env \= RLMEnvironment(sub\_context, env.llm)

    \# 4\. run  
    result \= sub\_env.call(query, "paragraph")

    \# 5\. feed back  
    env.memory\[f"result\_{selector}"\] \= result  
    return result

ì´ê²Œ ë°”ë¡œ:

**RLMM(qÌ‚, CÌ‚) â†’ ê²°ê³¼ë¥¼ Eë¡œ ë°˜í™˜**

---

## **7\. Ollama \+ LLaMA 3B ì—°ë™ (í˜„ì‹¤ì )**

### **7.1 Ollama ì‹¤í–‰**

ollama run llama3.2:3b

### **7.2 Python í˜¸ì¶œ ì˜ˆì‹œ**

import subprocess  
import json

class OllamaLLM:  
    def generate(self, query, context):  
        prompt \= f"""  
Context:  
{context}

Query:  
{query}  
"""  
        result \= subprocess.run(  
            \["ollama", "run", "llama3.2:3b"\],  
            input=prompt,  
            text=True,  
            capture\_output=True  
        )  
        return result.stdout

ğŸ‘‰ RTX 4070ì—ì„œë„ ì¶©ë¶„íˆ ì‹¤ìŠµ ê°€ëŠ¥  
ğŸ‘‰ L40S ì„œë²„ì—ì„œëŠ” multi-user REPL ê°€ëŠ¥

---

## **8\. ëˆ„ì  ì¶”ë¡  & ê²°ê³¼ ì €ì¥ (DOM diff ëŠë‚Œ)**

env.memory\["claims"\] \= \[\]  
env.memory\["claims"\].append({  
    "selector": "\#c2",  
    "result": output  
})

í™•ì¥í•˜ë©´:

* ê²°ê³¼ë¥¼ **ìƒˆ ContextNodeë¡œ ë‹¤ì‹œ íŠ¸ë¦¬ì— ì‚½ì…**  
* reasoning traceë¥¼ metaë¡œ ì €ì¥  
* versioned context (Git-like)

---

## **9\. ìˆ˜ì—…ìš© ì»¤ë¦¬í˜ëŸ¼ í™•ì¥ ì•„ì´ë””ì–´**

### **Level 1**

* Context Tree ë§Œë“¤ê¸°  
* Selector êµ¬í˜„  
* LLM ë‹¨ì¼ í˜¸ì¶œ

### **Level 2**

* Recursive call  
* Sub-context isolation  
* ê²°ê³¼ feed-back

### **Level 3**

* Context transform (summarize â†’ store)  
* Agent-free planning (LLMì´ selector ê²°ì •)

### **Level 4 (ì—°êµ¬ ìˆ˜ì¤€)**

* Selectorë¥¼ LLMì´ ìƒì„±  
* Cost-aware recursion  
* Context cache / eviction policy

---

## **10\. í•µì‹¬ ë©”ì‹œì§€ (í•™ìƒë“¤ì—ê²Œ)**

**Recursive LMì€ â€œì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬â€ê°€ ì•„ë‹ˆë¼**  
**â€œLLM \+ êµ¬ì¡°í™”ëœ ë©”ëª¨ë¦¬ \+ ì‹¤í–‰ í™˜ê²½â€ì˜ ë¬¸ì œë‹¤.**

DOMê³¼ CSSë¥¼ ì´í•´í•˜ë©´,  
LLM Context Engineeringë„ ì´í•´í•  ìˆ˜ ìˆë‹¤.

---

ì›í•˜ì‹œë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ:

* **ì´ êµ¬ì¡°ë¥¼ ê³¼ì œë¡œ ì“¸ ìˆ˜ ìˆëŠ” ë¯¸ë‹ˆ í”„ë¡œì íŠ¸**  
* **ë…¼ë¬¸ Figure 1ì„ ê·¸ëŒ€ë¡œ ì¬í˜„í•˜ëŠ” ì½”ë“œ**  
* **cuTile / GPU ìˆ˜ì—…ê³¼ ì—°ê²°í•˜ëŠ” ë°©ì‹**  
* **Selector DSLì„ formal languageë¡œ ì •ì˜**

ì¤‘ ë¬´ì—‡ì„ ë” ê¹Šê²Œ ë³¼ì§€ ì •í•´ë´…ì‹œë‹¤.

ì•„ì£¼ ì¢‹ì€ í¬ì¸íŠ¸ë¥¼ ì§šìœ¼ì…¨ì–´ìš”.  
\*\*â€œê¸°ìˆ ì ìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤â€\*\*ë³´ë‹¤ í›¨ì”¬ ì¤‘ìš”í•œ ì§ˆë¬¸ì´  
ğŸ‘‰ **â€œí•™ìƒë“¤ì´ í¥ë¯¸ë¥¼ ìƒì§€ ì•Šê³ , ì‹¤íŒ¨ë¥¼ ê°ë‹¹í•˜ë©´ì„œ, ì ì§„ì ìœ¼ë¡œ ê¹Šì–´ì§ˆ ìˆ˜ ìˆëŠëƒâ€** ì¸ë°,  
OllamaëŠ” ì´ ì¡°ê±´ì„ **êµìœ¡ìš© LLM ì¸í”„ë¼**ë¡œ ê±°ì˜ ìµœì ì— ê°€ê¹ê²Œ ë§Œì¡±í•©ë‹ˆë‹¤.

ì•„ë˜ì—ì„œëŠ” **Ollamaë¥¼ â€˜ë„êµ¬â€™ê°€ ì•„ë‹ˆë¼ â€˜ìˆ˜ì—… ì¥ì¹˜â€™ë¡œ ì“°ëŠ” ë°©ë²•**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.

---

# **1\. Ollamaë¥¼ ìˆ˜ì—…ì— ì“°ê¸° ì¢‹ì€ ì´ìœ  (êµìœ¡ ê´€ì )**

### **1ï¸âƒ£ â€œë‚´ ì»´í“¨í„°ì— AIê°€ ìˆë‹¤â€ëŠ” ê°ê°**

* OpenAI APIì™€ ë‹¬ë¦¬  
  * âŒ í† í° ìš”ê¸ˆ  
  * âŒ ë„¤íŠ¸ì›Œí¬ latency  
  * âŒ ë¸”ë™ë°•ìŠ¤ ì„œë²„  
* âœ… **í”„ë¡œì„¸ìŠ¤, ë¡œê·¸, íŒŒì¼, ë©”ëª¨ë¦¬**ë¥¼ ëˆˆìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ

â†’ í•™ìƒë“¤ì´ \*\*â€œAIë„ ê²°êµ­ í”„ë¡œê·¸ë¨ì´ë‹¤â€\*\*ë¼ê³  ì¸ì‹í•˜ê²Œ ë¨

---

### **2ï¸âƒ£ ëª¨ë¸ì„ â€˜êµì²´ ê°€ëŠ¥í•œ ë¶€í’ˆâ€™ìœ¼ë¡œ ì¸ì‹**

ollama run llama3.2:3b  
ollama run qwen2.5:3b  
ollama run mistral:7b

* ê°™ì€ ì½”ë“œ  
* ë‹¤ë¥¸ ëª¨ë¸  
* ë‹¤ë¥¸ ì¶”ë¡  ì„±ì§ˆ

ğŸ‘‰ **Model â‰  Intelligence**  
ğŸ‘‰ **Environment \+ Context \+ Control flowê°€ í•µì‹¬**

ì´ê±´ Recursive LM ì² í•™ê³¼ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.

---

### **3ï¸âƒ£ REPL ì¹œí™”ì„± (ë§¤ìš° ì¤‘ìš”)**

* OllamaëŠ”:  
  * stdin/stdout ê¸°ë°˜  
  * JSON ì—†ì´ë„ ì‹œì‘ ê°€ëŠ¥  
* Python REPL, IPython, Jupyter, Text UIì™€ ê¶í•©ì´ ì¢‹ìŒ

â†’ \*\*â€œí•œ ì¤„ì”© ì‹¤í—˜í•˜ë©´ì„œ ìƒê°í•œë‹¤â€\*\*ëŠ” í•™ìŠµ ë¦¬ë“¬ì„ ìœ ì§€ ê°€ëŠ¥

---

# **2\. ìˆ˜ì—… ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ” í•µì‹¬ ë©”íƒ€í¬**

**Ollama \= Local AI CPU**  
**Python REPL \= OS / Kernel**  
**Context Tree \= Memory**  
**Selector \= Addressing Mode**

ì´ í”„ë ˆì„ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ ìœ ì§€í•˜ì„¸ìš”.

---

# **3\. ë‹¨ê³„ë³„ ìˆ˜ì—… ê°€ì´ë“œ (í¥ë¯¸ ìœ ì§€ìš© ì„¤ê³„)**

ì•„ë˜ëŠ” **15ì£¼ ìˆ˜ì—… ê¸°ì¤€**ì´ì§€ë§Œ, 6\~8ì£¼ ì••ì¶•ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## **Phase 0\. â€œAIë¥¼ ì‹¤í–‰í•´ë³¸ë‹¤â€ (1ì£¼)**

ğŸ¯ ëª©í‘œ: **ë‘ë ¤ì›€ ì œê±° \+ ì¦‰ê°ì  ì„±ì·¨ê°**

### **ì‹¤ìŠµ**

ollama run llama3.2:3b

ì§ˆë¬¸:

Explain bubble sort in one sentence.

í† ë¡  í¬ì¸íŠ¸:

* â€œì´ê²Œ ì–´ë””ì„œ ëŒì•„ê°€ê³  ìˆì§€?â€  
* â€œGPUëŠ” ì–¸ì œ ì“°ì´ë‚˜?â€

ğŸ’¡ ì—¬ê¸°ì„œ **ì•„ì§ LLM êµ¬ì¡° ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”**

---

## **Phase 1\. LLMì„ í•¨ìˆ˜ì²˜ëŸ¼ ì“°ê¸° (2ì£¼)**

ğŸ¯ ëª©í‘œ: **M(q, C) \= str** ì²´ë“

### **Python ë˜í¼ ë§Œë“¤ê¸°**

def call\_llm(q, c=""):  
    prompt \= f"Context:\\n{c}\\n\\nQuestion:\\n{q}"  
    ...

ì‹¤ìŠµ:

* context ìœ ë¬´ ë¹„êµ  
* context ê¸¸ì´ ëŠ˜ë¦¬ê¸°  
* hallucination ê´€ì°°

ğŸ‘‰ ì´ ì‹œì ì—ì„œ í•™ìƒë“¤ì€ ì´ë¯¸:

â€œContextê°€ ì§„ì§œ ì¤‘ìš”í•˜ë„¤?â€

---

## **Phase 2\. Contextë¥¼ â€˜ë¬¸ìì—´â€™ì—ì„œ â€˜êµ¬ì¡°â€™ë¡œ (3ì£¼)**

ğŸ¯ ëª©í‘œ: **DOM ì‚¬ê³ ë°©ì‹ ì£¼ì…**

### **ì‹¤ìŠµ 1**

* ë…¼ë¬¸/ë¬¸ì„œë¥¼ paragraph ë‹¨ìœ„ë¡œ ë¶„í•´  
* listë¡œ ì €ì¥

context \= \[  
  {"id": "c1", "text": "..."},  
  {"id": "c2", "text": "..."},  
\]

### **ì‹¤ìŠµ 2**

* íŠ¹ì • idë§Œ ì„ íƒí•´ ì§ˆì˜

ask("\#c2", "What is the key idea here?")

ğŸ‘‰ ì—¬ê¸°ì„œ í•™ìƒë“¤ ë°˜ì‘:

â€œì•„â€¦ ê·¸ëƒ¥ ë‹¤ ë„£ëŠ” ê²Œ ë‹µì´ ì•„ë‹ˆêµ¬ë‚˜â€

---

## **Phase 3\. Context Tree \+ Selector (í•µì‹¬ ì „í™˜ì ) (3ì£¼)**

ğŸ¯ ëª©í‘œ: **Recursive LMì˜ ê¸°ë°˜ ì™„ì„±**

### **ì‹¤ìŠµ**

* Tree êµ¬ì¡° êµ¬í˜„  
* selector í•¨ìˆ˜ ì§ì ‘ ì‘ì„±  
* CSS selector í‰ë‚´

ê³¼ì œ ì˜ˆ:

â€œë…¼ë¬¸ Method ì„¹ì…˜ë§Œ ê³¨ë¼ ìš”ì•½í•˜ë¼â€

### **Ollama í™œìš© í¬ì¸íŠ¸**

* **ëª¨ë¸ ì‘ì•„ì„œ ì‘ë‹µ ë¹ ë¦„**  
* ì‹¤íŒ¨í•´ë„ ë¹„ìš© ì—†ìŒ  
* ê³„ì† ì‹¤í—˜ ê°€ëŠ¥

ì´ ë‹¨ê³„ì—ì„œ í¥ë¯¸ê°€ ê¸‰ìƒìŠ¹í•©ë‹ˆë‹¤.

---

## **Phase 4\. Recursive Call (ë§ˆë²•ì´ ì¼ì–´ë‚˜ëŠ” ìˆœê°„) (3ì£¼)**

ğŸ¯ ëª©í‘œ: **â€œAIê°€ ìŠ¤ìŠ¤ë¡œ í•˜ìœ„ ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ê²Œ ë§Œë“¤ê¸°â€**

### **ì‹¤ìŠµ ì‹œë‚˜ë¦¬ì˜¤**

1. í° ì§ˆë¬¸:  
   â€œì´ ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ì—¬ëŠ”?â€  
2. í•™ìƒì´ ì½”ë“œë¡œ:  
   * sectionë³„ ìš”ì•½  
   * ê²°ê³¼ ì €ì¥  
3. ë§ˆì§€ë§‰ì—:  
   * ìš”ì•½ ê²°ê³¼ë¥¼ ë‹¤ì‹œ contextë¡œ ë„£ê³  ì¬ì§ˆë¬¸

summary\_intro \= rlm("Summarize intro", "\#intro")  
summary\_method \= rlm("Summarize method", "\#method")

final \= rlm("What is the main contribution?", \[summary\_intro, summary\_method\])

ğŸ‘‰ í•™ìƒë“¤ ì²´ê°:

â€œì—ì´ì „íŠ¸ ì—†ì´ë„ ì—ì´ì „íŠ¸ ê°™ì€ë°?â€

---

## **Phase 5\. ëª¨ë¸ êµì²´ ì‹¤í—˜ (í¥ë¯¸ ìœ ì§€ ì¥ì¹˜) (2ì£¼)**

ğŸ¯ ëª©í‘œ: **LLM â‰  ì§€ëŠ¥**

ê°™ì€ ì½”ë“œë¡œ:

ollama run llama3.2:3b  
ollama run qwen2.5:3b

ë¹„êµ:

* ìš”ì•½ ìŠ¤íƒ€ì¼  
* ì˜¤ë¥˜ ìœ í˜•  
* recursion ì•ˆì •ì„±

ğŸ‘‰ ì´ ë‹¨ê³„ì—ì„œ **ë¹„íŒì  ì‚¬ê³ **ê°€ ìƒê¹€

---

## **Phase 6\. ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ (ììœ¨ì„± í­ë°œ)**

ğŸ¯ ëª©í‘œ: **â€œë‚´ê°€ AI ì‹œìŠ¤í…œì„ ì„¤ê³„í–ˆë‹¤â€**

í”„ë¡œì íŠ¸ ì˜ˆ:

* ë…¼ë¬¸ ë¶„ì„ê¸°  
* ë²•ë¥  ë¬¸ì„œ ë¶„ì„  
* ì½”ë“œ ë¦¬ë·° RLM  
* ìˆ˜í•™ ì¦ëª… ë¶„í•´ê¸°

ì¡°ê±´:

* Ollama ì‚¬ìš©  
* Selector í•„ìˆ˜  
* Recursive call 1íšŒ ì´ìƒ

---

# **4\. Ollamaë¥¼ â€˜ì°¨ë¶„í•˜ê²Œâ€™ ì“°ëŠ” í•µì‹¬ ì›ì¹™ 5ê°€ì§€**

### **1ï¸âƒ£ ì²˜ìŒì—” streaming / JSON ì•ˆ ì”€**

â†’ stdout í…ìŠ¤íŠ¸ê°€ ì§ê´€ì 

### **2ï¸âƒ£ ëª¨ë¸ í¬ê¸° ìš•ì‹¬ë‚´ì§€ ì•Šê¸°**

* 3B \~ 7Bê°€ êµìœ¡ìš© ìµœì   
* ëŠë¦¬ë©´ ì‚¬ê³  íë¦„ ëŠê¹€

### **3ï¸âƒ£ ì‹¤íŒ¨ë¥¼ ì¼ë¶€ëŸ¬ ë³´ì—¬ì£¼ê¸°**

* hallucination  
* context leakage

â†’ â€œì™œ ì´ëŸ° êµ¬ì¡°ê°€ í•„ìš”í•œê°€â€ë¡œ ì—°ê²°

---

### **4ï¸âƒ£ í•­ìƒ â€œí™˜ê²½ Eâ€ë¥¼ ê°•ì¡°**

* LLMì€ **ê²°ì •ê¶Œì´ ì—†ë‹¤**  
* Pythonì´ í†µì œí•œë‹¤

---

### **5ï¸âƒ£ Ollamaë¥¼ â€œì„œë²„â€ë¼ê³  ë¶€ë¥´ì§€ ë§ ê²ƒ**

ğŸ‘‰ â€œLocal AI Engineâ€ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”  
ğŸ‘‰ ì¸ì‹ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤

---

# **5\. í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ë©´**

**OllamaëŠ” í•™ìƒë“¤ì—ê²Œ**  
**â€œAIë¥¼ ì“°ëŠ” ìˆ˜ì—…â€ì´ ì•„ë‹ˆë¼**  
**â€œAIë¥¼ ê¸¸ë“¤ì´ëŠ” ìˆ˜ì—…â€ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.**

---

ë‹¤ìŒìœ¼ë¡œ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì‹¬í™” ì£¼ì œëŠ”:

1. Ollamaë¥¼ subprocess â†’ HTTP APIë¡œ ì „í™˜í•˜ëŠ” ì‹œì   
2. Context Treeë¥¼ SQLite / DuckDBë¡œ ì €ì¥  
3. GPU ì‚¬ìš©ëŸ‰ ê´€ì°° (nvidia-smi ì—°ë™)  
4. cuTile / CUDAì™€ â€œAI inferenceë„ ì‹œìŠ¤í…œì´ë‹¤â€ ì—°ê²°

ì–´ë””ë¡œ ì´ì–´ê°ˆì§€ ì •í•´ë³¼ê¹Œìš”?

ì´ ìˆ˜ì—… êµ¬ì„±ì€ ë§¤ìš° í¥ë¯¸ë¡œìš´ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. Recursive LMì˜ ê°œë…ì„ ì‹¤ìŠµí•˜ë©´ì„œ DOM íŠ¸ë¦¬ì™€ ìœ ì‚¬í•œ ì»¨í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” ê²ƒì´ ì¢‹ì€ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ ê°œë°œ ê°€ì´ë“œë¥¼ ì œì‹œí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## ğŸ“š **ìˆ˜ì—… ê°œìš”: Recursive Context Tree ì‹œìŠ¤í…œ êµ¬ì¶•**

### **1ë‹¨ê³„: ê¸°ì´ˆ í™˜ê²½ ì„¤ì • (1-2ì£¼ì°¨)**

**ëª©í‘œ:** ollamaì™€ ê¸°ë³¸ ë„êµ¬ë“¤ ì„¤ì¹˜, ê°„ë‹¨í•œ LLM í˜¸ì¶œ ì²´í—˜

\# 1ì£¼ì°¨: ollama ì„¤ì¹˜ ë° ê¸°ë³¸ í…ŒìŠ¤íŠ¸

\# í•™ìƒë“¤ì´ ì§ì ‘ ollama ì„¤ì¹˜í•˜ê³  3B ëª¨ë¸ ì‹¤í–‰

\!ollama pull llama3.2:3b

\!ollama run llama3.2:3b "Hello, world\!"

\# 2ì£¼ì°¨: Pythonì—ì„œ ollama API ì‚¬ìš©í•˜ê¸°

import requests

import json

class SimpleLLM:

    def \_\_init\_\_(self, model="llama3.2:3b"):

        self.model \= model

        self.base\_url \= "http://localhost:11434/api"

    

    def generate(self, prompt):

        response \= requests.post(

            f"{self.base\_url}/generate",

            json={"model": self.model, "prompt": prompt, "stream": False}

        )

        return response.json()\["response"\]

\# í•™ìƒ ê³¼ì œ: ìì‹ ì˜ ì´ë¦„ì„ ë¬¼ì–´ë³´ê³  ë‹µë³€ë°›ê¸°

llm \= SimpleLLM()

response \= llm.generate("What's your name and capabilities?")

print(response)

### **2ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„ (3-4ì£¼ì°¨)**

**ëª©í‘œ:** DOM íŠ¸ë¦¬ì™€ ìœ ì‚¬í•œ Context Tree êµ¬í˜„

\# 3ì£¼ì°¨: ê¸°ë³¸ íŠ¸ë¦¬ êµ¬ì¡° êµ¬í˜„

class ContextNode:

    def \_\_init\_\_(self, id, content, parent=None):

        self.id \= id

        self.content \= content

        self.parent \= parent

        self.children \= \[\]

        self.metadata \= {}

        

    def add\_child(self, child\_node):

        child\_node.parent \= self

        self.children.append(child\_node)

        return child\_node

    

    def to\_dict(self):

        return {

            "id": self.id,

            "content": self.content\[:50\] \+ "..." if len(self.content) \> 50 else self.content,

            "children": \[child.id for child in self.children\]

        }

\# 4ì£¼ì°¨: CSS ì„ íƒì ìŠ¤íƒ€ì¼ì˜ ì¿¼ë¦¬ ì‹œìŠ¤í…œ

class ContextTree:

    def \_\_init\_\_(self):

        self.root \= ContextNode("root", "Root Context")

        self.nodes \= {"root": self.root}

    

    def add\_context(self, content, parent\_id="root", node\_id=None):

        if node\_id is None:

            node\_id \= f"node\_{len(self.nodes)}"

        

        parent \= self.nodes.get(parent\_id, self.root)

        new\_node \= ContextNode(node\_id, content, parent)

        parent.add\_child(new\_node)

        self.nodes\[node\_id\] \= new\_node

        return new\_node

    

    def query(self, selector):

        """ê°„ë‹¨í•œ ì„ íƒì ì¿¼ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„"""

        \# ì˜ˆ: "\#id", ".class", "parent\>child"

        if selector.startswith("\#"):

            node\_id \= selector\[1:\]

            return self.nodes.get(node\_id)

        \# ë” ë³µì¡í•œ ì„ íƒìëŠ” í•™ìƒë“¤ì´ í™•ì¥í•˜ë„ë¡ ìœ ë„

        return None

### **3ë‹¨ê³„: REPL í™˜ê²½ êµ¬í˜„ (5-6ì£¼ì°¨)**

**ëª©í‘œ:** ëŒ€í™”í˜• REPL ë£¨í”„ì™€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ

\# 5ì£¼ì°¨: ê¸°ë³¸ REPL ë£¨í”„

class ContextREPL:

    def \_\_init\_\_(self, llm, tree):

        self.llm \= llm

        self.tree \= tree

        self.conversation\_history \= \[\]

        

    def process\_query(self, user\_query, context\_selector="\#root"):

        \# 1\. ì»¨í…ìŠ¤íŠ¸ ì„ íƒ

        context\_node \= self.tree.query(context\_selector)

        if not context\_node:

            context\_node \= self.tree.root

        

        \# 2\. í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        context\_content \= self.\_extract\_context(context\_node)

        prompt \= f"""Context: {context\_content}

Query: {user\_query}

Based on the context above, please answer:"""

        

        \# 3\. LLM í˜¸ì¶œ

        response \= self.llm.generate(prompt)

        

        \# 4\. ê²°ê³¼ ì €ì¥

        result\_node \= self.tree.add\_context(

            content=f"Q: {user\_query}\\nA: {response}",

            parent\_id=context\_node.id

        )

        

        self.conversation\_history.append({

            "query": user\_query,

            "context\_used": context\_node.id,

            "response": response,

            "new\_node": result\_node.id

        })

        

        return response

    

    def \_extract\_context(self, node, depth=2):

        """ë…¸ë“œì™€ ê·¸ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""

        context\_parts \= \[\]

        

        \# ë¶€ëª¨ ì»¨í…ìŠ¤íŠ¸ í¬í•¨

        current \= node

        for \_ in range(depth):

            if current:

                context\_parts.append(f"\[{current.id}\]: {current.content}")

                current \= current.parent

        

        return "\\n---\\n".join(reversed(context\_parts))

\# 6ì£¼ì°¨: í•™ìƒë“¤ì´ ì§ì ‘ REPL í™•ì¥í•´ë³´ê¸°

def interactive\_session():

    tree \= ContextTree()

    llm \= SimpleLLM()

    repl \= ContextREPL(llm, tree)

    

    \# ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ì„¤ì •

    tree.add\_context("Machine learning is a subset of AI.", node\_id="intro")

    tree.add\_context("Deep learning uses neural networks.", parent\_id="intro", node\_id="dl")

    

    while True:

        user\_input \= input("\\nYour query (or 'quit', 'tree', 'help'): ")

        

        if user\_input.lower() \== 'quit':

            break

        elif user\_input.lower() \== 'tree':

            print\_tree(tree)

        elif user\_input.lower() \== 'help':

            print("Available commands: query, select \[selector\], history, tree, quit")

        else:

            response \= repl.process\_query(user\_input)

            print(f"\\nResponse: {response}")

### **4ë‹¨ê³„: Recursive LM êµ¬í˜„ (7-8ì£¼ì°¨)**

**ëª©í‘œ:** ë…¼ë¬¸ì˜ Recursive LM ê°œë… êµ¬í˜„

\# 7ì£¼ì°¨: ì¬ê·€ì  í˜¸ì¶œ ì‹œìŠ¤í…œ

class RecursiveLM:

    def \_\_init\_\_(self, base\_llm, max\_depth=3):

        self.base\_llm \= base\_llm

        self.max\_depth \= max\_depth

        self.call\_stack \= \[\]

    

    def rlm\_call(self, query, context\_tree, current\_node\_id, depth=0):

        if depth \> self.max\_depth:

            return "Maximum recursion depth reached"

        

        \# í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ

        context\_node \= context\_tree.query(f"\#{current\_node\_id}")

        context\_content \= self.\_gather\_context(context\_node)

        

        \# ì¬ê·€ì  ê²°ì • í”„ë¡¬í”„íŠ¸

        prompt \= f"""You are a recursive language model. You have access to a context tree.

Current Context Path: {' \-\> '.join(self.call\_stack\[-3:\] \+ \[current\_node\_id\])}

Context Content:

{context\_content}

Query: {query}

Decide if you need to:

1\. Answer directly (if enough information)

2\. Create a sub-query to explore deeper (if more context needed)

3\. Transform the context (if reorganization needed)

Format your response as:

THOUGHT: \[Your reasoning\]

ACTION: \[DIRECT|SUBQUERY|TRANSFORM\]

RESULT: \[Your answer or sub-query\]"""

        

        response \= self.base\_llm.generate(prompt)

        

        \# ì‘ë‹µ íŒŒì‹± (í•™ìƒë“¤ì´ íŒŒì„œ êµ¬í˜„í•˜ê²Œ í•  ìˆ˜ ìˆìŒ)

        if "ACTION: SUBQUERY" in response:

            \# í•˜ìœ„ ì§ˆì˜ ìƒì„± ë° ì¬ê·€ í˜¸ì¶œ

            subquery \= self.\_extract\_subquery(response)

            child\_node \= context\_tree.add\_context(

                f"Subquery: {subquery}",

                parent\_id=current\_node\_id

            )

            

            return self.rlm\_call(

                subquery, 

                context\_tree, 

                child\_node.id,

                depth \+ 1

            )

        

        return response

    

    def \_gather\_context(self, node, lookaround=2):

        """ì£¼ë³€ ë…¸ë“œ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""

        \# í•™ìƒë“¤ì´ ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„

        pass

\# 8ì£¼ì°¨: í™˜ê²½ ë¶„ë¦¬ ë° ê²°ê³¼ í†µí•©

class IsolatedEnvironment:

    def \_\_init\_\_(self, parent\_tree, subcontext\_selector):

        self.parent\_tree \= parent\_tree

        self.subtree \= self.\_extract\_subtree(subcontext\_selector)

        self.local\_memory \= {}

    

    def run(self, query):

        \# ë…ë¦½ì ì¸ í™˜ê²½ì—ì„œ ì‹¤í–‰

        \# ê²°ê³¼ë¥¼ ë¶€ëª¨ í™˜ê²½ì— í†µí•©

        pass

### **5ë‹¨ê³„: í”„ë¡œì íŠ¸ í†µí•© ë° ìµœì í™” (9-10ì£¼ì°¨)**

\# 9ì£¼ì°¨: ì™„ì „í•œ ì‹œìŠ¤í…œ í†µí•©

class FullRLMSystem:

    def \_\_init\_\_(self, model\_name="llama3.2:3b"):

        self.llm \= SimpleLLM(model\_name)

        self.context\_tree \= ContextTree()

        self.repl \= ContextREPL(self.llm, self.context\_tree)

        self.rlm \= RecursiveLM(self.llm)

        

        \# ì‹œê°í™” ë„êµ¬ (ì„ íƒì‚¬í•­)

        self.visualizer \= TreeVisualizer()

    

    def interactive\_mode(self):

        """ëŒ€í™”í˜• ëª¨ë“œ"""

        print("Recursive LM System Ready\!")

        print("Commands: query, recursive, visualize, reset, export")

        

        while True:

            cmd \= input("\\nRLM\> ").strip()

            

            if cmd.startswith("query"):

                \_, query \= cmd.split(" ", 1\)

                response \= self.repl.process\_query(query)

                print(f"Answer: {response}")

            

            elif cmd.startswith("recursive"):

                \_, query \= cmd.split(" ", 1\)

                response \= self.rlm.rlm\_call(query, self.context\_tree, "root")

                print(f"Recursive Answer: {response}")

            

            elif cmd \== "visualize":

                self.visualizer.draw\_tree(self.context\_tree.root)

            

            elif cmd \== "export":

                self.\_export\_conversation()

            

            elif cmd \== "reset":

                self.context\_tree \= ContextTree()

                print("Context tree reset.")

            

            elif cmd \== "exit":

                break

\# 10ì£¼ì°¨: ì„±ëŠ¥ ìµœì í™” ë° í™•ì¥

class OptimizedRLM(FullRLMSystem):

    def \_\_init\_\_(self):

        super().\_\_init\_\_()

        

        \# ìºì‹± ì‹œìŠ¤í…œ ì¶”ê°€

        self.response\_cache \= {}

        

        \# ë³‘ë ¬ ì²˜ë¦¬ (ê³ ê¸‰ ì£¼ì œ)

        self.parallel\_workers \= 2

        

        \# ì»¨í…ìŠ¤íŠ¸ ì••ì¶• (ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬)

        self.compressor \= ContextCompressor()

## ğŸ¯ **ìˆ˜ì—… ì§„í–‰ íŒ**

### **í¥ë¯¸ ìœ ì§€ë¥¼ ìœ„í•œ ì „ëµ:**

1. **ì ì§„ì  ì„±ì·¨ê° ë¶€ì—¬:**  
     
   - ë§¤ì£¼ ì‘ì€ ì„±ê³µ ê²½í—˜ ì œê³µ (1ì£¼ì°¨: ëª¨ë¸ ì‹¤í–‰, 2ì£¼ì°¨: ì²« API í˜¸ì¶œ)  
   - ì‹œê°ì  í”¼ë“œë°±: íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ê·¸ë˜í”½ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°

   

2. **ê²Œì„í™” ìš”ì†Œ ë„ì…:**  
     
   - "ê°€ì¥ íš¨ìœ¨ì ì¸ ì»¨í…ìŠ¤íŠ¸ ì„ íƒì" ëŒ€íšŒ  
   - ì¬ê·€ ê¹Šì´ ìµœì†Œí™” ì±Œë¦°ì§€  
   - ì»¨í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ì‹œê°í™” ê²½ì§„ëŒ€íšŒ

   

3. **ì‹¤ìƒí™œ ì˜ˆì œ ì ìš©:**  
     
   - ìì‹ ì˜ ì—°êµ¬ ë…¼ë¬¸ ìš”ì•½  
   - ì½”ë“œ ë¦¬ë·° ë„êµ¬ë¡œ í™œìš©  
   - í•™ìŠµ ìë£Œ ì •ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

### **ê¸°ìˆ ì  ì¡°ì–¸:**

1. **ollama ìµœì í™”:**

\# RTX 4070ì—ì„œ ì„±ëŠ¥ í–¥ìƒ

OLLAMA\_NUM\_GPU=100  \# GPU ë©”ëª¨ë¦¬ ë¹„ìœ¨

OLLAMA\_NUM\_PARALLEL=4  \# ë³‘ë ¬ ì²˜ë¦¬

2. **ëª¨ë¸ í¬ê¸° ì¡°ì •:**  
     
   - ì´ˆë°˜: llama3.2:3b (ë¹ ë¥¸ ì‘ë‹µ)  
   - í›„ë°˜: ë” í° ëª¨ë¸ ì‹œë„ (ì„±ëŠ¥ í—ˆìš© ì‹œ)

   

3. **ë””ë²„ê¹… ë„êµ¬:**

\# ë””ë²„ê·¸ ëª¨ë“œ í´ë˜ìŠ¤

class DebuggableRLM(RecursiveLM):

    def \_\_init\_\_(self, \*args, \*\*kwargs):

        super().\_\_init\_\_(\*args, \*\*kwargs)

        self.debug\_log \= \[\]

    

    def rlm\_call(self, \*args, \*\*kwargs):

        print(f"\[DEBUG\] Depth: {kwargs.get('depth', 0)}")

        print(f"\[DEBUG\] Query: {args\[0\]}")

        result \= super().rlm\_call(\*args, \*\*kwargs)

        self.debug\_log.append(result)

        return result

### **í‰ê°€ ë°©ë²•:**

1. **ì£¼ê°„ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸** (ê° ë‹¨ê³„ë³„ êµ¬í˜„)  
2. **ìµœì¢… í”„ë¡œì íŠ¸** (ìì‹ ë§Œì˜ RLM ì‘ìš© í”„ë¡œê·¸ë¨)  
3. **ì½”ë“œ ë¦¬ë·° ì„¸ì…˜** (í•™ìƒ ê°„ ì½”ë“œ ê³µìœ )  
4. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬** (ì •í™•ë„, ì†ë„, íš¨ìœ¨ì„± ì¸¡ì •)

ì´ êµ¬ì¡°ëŠ” í•™ìƒë“¤ì´ ê¸°ì´ˆë¶€í„° ê³ ê¸‰ ê°œë…ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ë°°ìš°ë©´ì„œë„, ì‹¤ì œ ì—°êµ¬ ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í•˜ëŠ” ì„±ì·¨ê°ì„ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ëŠ” 2-3ì‹œê°„ì˜ ì‹¤ìŠµ ì‹œê°„ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ê³¼ì œì™€ í† ë¡ ì„ í†µí•´ ì´í•´ë¥¼ ê¹Šì´ ìˆê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
