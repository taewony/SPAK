<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Inference: Prefill & Decode</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.7;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: #fff;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.05);
        }
        h1 {
            text-align: center;
            color: #444;
            margin-bottom: 40px;
            border-bottom: 2px solid #ddd;
            padding-bottom: 15px;
        }
        h2 {
            color: #2c3e50;
            margin-top: 35px;
            border-left: 5px solid #3498db;
            padding-left: 15px;
        }
        .concept-box {
            background-color: #f0f7fb;
            border: 1px solid #d6e9c6;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .highlight {
            font-weight: bold;
            color: #e74c3c;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
        }
        th, td {
            padding: 12px;
            border: 1px solid #ddd;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .tag-compute {
            display: inline-block;
            background: #e1f5fe;
            color: #0288d1;
            padding: 2px 8px;
            border-radius: 12px;
            font-size: 0.85rem;
            font-weight: bold;
        }
        .tag-memory {
            display: inline-block;
            background: #fbe9e7;
            color: #d84315;
            padding: 2px 8px;
            border-radius: 12px;
            font-size: 0.85rem;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>LLM Inference Mechanics:<br>Prefill vs Decode</h1>
        
        <p>Large Language Model (LLM)ì˜ ì¶”ë¡  ê³¼ì •ì€ í¬ê²Œ <strong>Prefill</strong> ë‹¨ê³„ì™€ <strong>Decode</strong> ë‹¨ê³„ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ì´ ë‘ ë‹¨ê³„ëŠ” í•˜ë“œì›¨ì–´ ìì›ì„ ì‚¬ìš©í•˜ëŠ” íŠ¹ì„±ì´ ì™„ì „íˆ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì—ì„œ ê°ê° ë‹¤ë¥¸ ìµœì í™” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.</p>

        <section>
            <h2>1. Prefill Phase (The Processing Stage)</h2>
            <div class="concept-box">
                <strong>ì •ì˜:</strong> ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸(Prompt) ì „ì²´ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬, ì´ˆê¸° <strong>KV Cache(Key-Value Cache)</strong>ë¥¼ ìƒì„±í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. "Time to First Token (TTFT)" ì„±ëŠ¥ì„ ê²°ì •í•©ë‹ˆë‹¤.
            </div>
            
            <h3>ğŸ› ï¸ Engineering Characteristics</h3>
            <ul>
                <li><strong>Compute-Bound <span class="tag-compute">ì—°ì‚° ì¤‘ì‹¬</span>:</strong> ì…ë ¥ëœ ëª¨ë“  í† í°ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬(Matrix Multiplication)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ GPUì˜ ì—°ì‚° ì½”ì–´(CUDA Core/Tensor Core) í™œìš©ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.</li>
                <li><strong>Latency Sensitivity:</strong> ì‚¬ìš©ìê°€ ë‹µë³€ì„ ë°›ê¸°ê¹Œì§€ì˜ ëŒ€ê¸° ì‹œê°„ê³¼ ì§ê²°ë©ë‹ˆë‹¤.</li>
            </ul>

            <h3>ğŸ’¡ Optimization Points</h3>
            <ul>
                <li><strong>Prompt Caching:</strong> ë°˜ë³µë˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë‚˜ ë¬¸ì„œë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ KV Cacheì— ì €ì¥í•´ë‘ë©´ ì¬ì—°ì‚°ì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                <li><strong>Batching:</strong> ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ì—¬ëŸ¬ ìš”ì²­ì„ ë¬¶ì–´ì„œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•©ë‹ˆë‹¤.</li>
            </ul>
        </section>

        <section>
            <h2>2. Decode Phase (The Generation Stage)</h2>
            <div class="concept-box">
                <strong>ì •ì˜:</strong> ì²« ë²ˆì§¸ í† í°ì´ ìƒì„±ëœ ì´í›„, ëª¨ë¸ì´ í•œ ë²ˆì— í•˜ë‚˜ì”© ë‹¤ìŒ í† í°ì„ ìƒì„±(Auto-regressive generation)í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. "Tokens Per Second (TPS)" ì„±ëŠ¥ì„ ê²°ì •í•©ë‹ˆë‹¤.
            </div>

            <h3>ğŸ› ï¸ Engineering Characteristics</h3>
            <ul>
                <li><strong>Memory-Bound <span class="tag-memory">ë©”ëª¨ë¦¬ ì¤‘ì‹¬</span>:</strong> ê° í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ ê±°ëŒ€í•œ ëª¨ë¸ ê°€ì¤‘ì¹˜(Weights) ì „ì²´ì™€ ëˆ„ì ëœ KV Cacheë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ì—°ì‚°ëŸ‰ì— ë¹„í•´ ë°ì´í„° ì´ë™ëŸ‰ì´ ì••ë„ì ìœ¼ë¡œ ë§ìŠµë‹ˆë‹¤.</li>
                <li><strong>Low Compute Utilization:</strong> GPU ì½”ì–´ëŠ” ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠë¼(IDLE) ë…¸ëŠ” ì‹œê°„ì´ ë§ì•„ì§‘ë‹ˆë‹¤.</li>
            </ul>

            <h3>ğŸ’¡ Optimization Points</h3>
            <ul>
                <li><strong>KV Cache Optimization:</strong> PagedAttention(vLLM)ê³¼ ê°™ì€ ê¸°ìˆ ë¡œ ë©”ëª¨ë¦¬ íŒŒí¸í™”ë¥¼ ì¤„ì—¬ì•¼ í•©ë‹ˆë‹¤.</li>
                <li><strong>Quantization (ì–‘ìí™”):</strong> ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ FP16ì—ì„œ INT8, INT4ë¡œ ì¤„ì—¬ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ìš”êµ¬ëŸ‰ì„ ë‚®ì¶¥ë‹ˆë‹¤.</li>
                <li><strong>Speculative Decoding:</strong> ì‘ì€ ëª¨ë¸ì´ ë¯¸ë¦¬ ì—¬ëŸ¬ í† í°ì„ ì¶”ì¸¡í•˜ê³ , í° ëª¨ë¸ì´ ê²€ì¦í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ‘ê·¼ íšŸìˆ˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.</li>
            </ul>
        </section>

        <section>
            <h2>3. Summary & Comparison</h2>
            <table>
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>Prefill Phase</th>
                        <th>Decode Phase</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>ì£¼ ì‘ì—…</strong></td>
                        <td>í”„ë¡¬í”„íŠ¸ ì´í•´ ë° ì´ˆê¸° ìƒíƒœ ìƒì„±</td>
                        <td>í•œ ê¸€ìì”© ë‹µë³€ ìƒì„±</td>
                    </tr>
                    <tr>
                        <td><strong>ë³‘ëª© ì§€ì  (Bottleneck)</strong></td>
                        <td><span class="tag-compute">Compute (FLOPS)</span></td>
                        <td><span class="tag-memory">Memory Bandwidth (GB/s)</span></td>
                    </tr>
                    <tr>
                        <td><strong>ë³‘ë ¬ì„±</strong></td>
                        <td>ë†’ìŒ (ëª¨ë“  ì…ë ¥ í† í° ë™ì‹œ ì²˜ë¦¬)</td>
                        <td>ë‚®ìŒ (ìˆœì°¨ì  ì˜ì¡´ì„±)</td>
                    </tr>
                    <tr>
                        <td><strong>ì£¼ìš” ì§€í‘œ</strong></td>
                        <td>Time to First Token (TTFT)</td>
                        <td>Tokens Per Second (TPS)</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <p style="margin-top: 40px; color: #666; font-size: 0.9em; text-align: center;">
            Understanding these two phases is crucial for building efficient AI systems, especially when sizing GPUs and designing serving architectures.
        </p>
    </div>
</body>
</html>