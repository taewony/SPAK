<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SPAK: A Dual-Loop Cognitive Architecture for Systematic High-Performance Computing Engineering</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            max-width: 210mm;
            margin: 20px auto;
            padding: 20mm;
            background: #fff;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        
        h1, h2, h3, h4 {
            color: #2c3e50;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            font-weight: bold;
        }
        
        h1 {
            font-size: 24pt;
            text-align: center;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }
        
        h2 {
            font-size: 16pt;
            border-bottom: 1px solid #eee;
            padding-bottom: 5px;
        }
        
        h3 {
            font-size: 14pt;
        }
        
        h4 {
            font-size: 12pt;
            font-style: italic;
        }
        
        p {
            margin: 1em 0;
            text-align: justify;
            font-size: 11pt;
        }
        
        .abstract {
            background-color: #f8f9fa;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            font-style: italic;
        }
        
        .abstract h2 {
            font-size: 12pt;
            margin-top: 0;
            border-bottom: none;
        }
        
        .section {
            margin-bottom: 30px;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 10pt;
        }
        
        table, th, td {
            border: 1px solid #ddd;
        }
        
        th {
            background-color: #f2f2f2;
            padding: 10px;
            text-align: left;
            font-weight: bold;
        }
        
        td {
            padding: 8px 10px;
            vertical-align: top;
        }
        
        .figure {
            text-align: center;
            margin: 20px 0;
        }
        
        .figure img {
            max-width: 100%;
            height: auto;
        }
        
        .figure-caption {
            font-style: italic;
            font-size: 10pt;
            margin-top: 5px;
            color: #666;
        }
        
        code {
            font-family: 'Courier New', monospace;
            background-color: #f8f8f8;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 10pt;
        }
        
        pre {
            background-color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
            font-size: 10pt;
            border-left: 3px solid #3498db;
        }
        
        .algorithm {
            background-color: #f9f9f9;
            padding: 15px;
            border: 1px solid #ddd;
            margin: 20px 0;
        }
        
        .citation {
            color: #3498db;
            font-weight: bold;
        }
        
        .footnote {
            font-size: 9pt;
            color: #666;
            border-top: 1px solid #eee;
            padding-top: 10px;
            margin-top: 30px;
        }
        
        .author-list {
            text-align: center;
            margin: 20px 0;
            font-size: 11pt;
        }
        
        .author {
            display: inline-block;
            margin: 0 15px;
        }
        
        .affiliation {
            font-size: 9pt;
            color: #666;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .keywords {
            margin: 20px 0;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        
        .keyword {
            display: inline-block;
            background-color: #e3f2fd;
            padding: 3px 8px;
            margin: 2px;
            border-radius: 3px;
            font-size: 9pt;
        }
        
        .equation {
            text-align: center;
            margin: 20px 0;
            padding: 10px;
        }
        
        .equation-number {
            text-align: right;
            font-weight: bold;
        }
        
        .reference {
            font-size: 10pt;
            margin: 5px 0;
            padding-left: 20px;
            text-indent: -20px;
        }
        
        @media print {
            body {
                box-shadow: none;
                margin: 0;
                padding: 15mm;
            }
            
            h1 {
                font-size: 18pt;
            }
            
            h2 {
                font-size: 14pt;
            }
            
            h3 {
                font-size: 12pt;
            }
            
            p, li {
                font-size: 10pt;
            }
            
            .page-break {
                page-break-before: always;
            }
        }
        
        @media screen and (max-width: 768px) {
            body {
                padding: 10px;
                margin: 10px;
                box-shadow: none;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>SPAK: A Dual-Loop Cognitive Architecture for Systematic High-Performance Computing Engineering</h1>
        
        <div class="author-list">
            <div class="author">연구팀</div>
        </div>
        
        <div class="affiliation">
            시스템 엔지니어링 AI 연구실<br>
            논문 초안 버전 1.0
        </div>
    </div>
    
    <div class="abstract">
        <h2>Abstract</h2>
        <p>The automation of high-performance computing (HPC) kernel engineering faces a fundamental challenge: bridging the <strong>semantic gap</strong> between algorithmic innovation and hardware optimization. Current AI-assisted coding tools treat code generation as a singular task, failing to capture the <strong>hierarchical reasoning</strong> that expert engineers employ when designing performance-critical systems. We present <strong>SPAK</strong> (Systematic Performance-Aware Kernel engineering), a dual-loop cognitive architecture that formalizes the separation between <strong>abductive architectural search</strong> and <strong>inductive parameter optimization</strong>.</p>
        
        <p>SPAK introduces three key innovations: (1) A <strong>strategic planning loop</strong> that performs invariant verification and algorithm design on CPU resources, (2) A <strong>tactical execution loop</strong> that implements and tunes kernels on GPU hardware, and (3) <strong>Engineering Instruction Guides</strong> as the formal interface between these loops. We validate SPAK through two comprehensive case studies: Fused Multi-Head Attention (FMHA) optimization achieving <strong>421× speedup</strong> over naive baselines and Matrix Multiplication optimization reaching <strong>98% of cuBLAS performance</strong>. Our results demonstrate that separating cognitive concerns enables more efficient hardware utilization and produces more reliable optimization artifacts than end-to-end approaches.</p>
    </div>
    
    <div class="keywords">
        <strong>Keywords:</strong>
        <span class="keyword">High-Performance Computing</span>
        <span class="keyword">AI-Assisted Engineering</span>
        <span class="keyword">Dual-Loop Architecture</span>
        <span class="keyword">Kernel Optimization</span>
        <span class="keyword">Abductive Reasoning</span>
        <span class="keyword">GPU Programming</span>
    </div>
    
    <div class="section">
        <h2>1. Introduction: The Cognitive Divide in Performance Engineering</h2>
        
        <h3>1.1 The Challenge of Automated HPC Engineering</h3>
        <p>High-performance computing requires simultaneous consideration of multiple abstraction layers: mathematical correctness, algorithmic efficiency, memory hierarchy optimization, and hardware-specific tuning. Current approaches suffer from:</p>
        
        <ol>
            <li><strong>Monolithic Reasoning</strong>: AI coding assistants treat optimization as a single-step generation problem, mixing architectural decisions with implementation details.</li>
            <li><strong>Hardware Inefficiency</strong>: Expensive GPU resources are wasted on trial-and-error search through unconstrained solution spaces.</li>
            <li><strong>Lack of Verifiability</strong>: Generated code lacks formal verification steps, making correctness guarantees difficult.</li>
        </ol>
        
        <h3>1.2 The Expert Engineer's Cognitive Strategy</h3>
        <p>Expert HPC engineers employ a systematic two-phase approach:</p>
        
        <div class="algorithm">
            <p><strong>Phase 1 (Strategic)</strong>: "Does this algorithm work? What are its fundamental bottlenecks?"</p>
            <ul>
                <li>Performed on CPU with low-cost resources</li>
                <li>Focus: Mathematical verification, asymptotic analysis, algorithm design</li>
                <li>Reasoning mode: Abductive (inference to best explanation)</li>
            </ul>
            
            <p><strong>Phase 2 (Tactical)</strong>: "How do I implement this optimally on specific hardware?"</p>
            <ul>
                <li>Performed on GPU with specialized resources</li>
                <li>Focus: Implementation, parameter tuning, performance measurement</li>
                <li>Reasoning mode: Inductive/experimental</li>
            </ul>
        </div>
        
        <h3>1.3 Core Contributions</h3>
        <p>This paper makes the following contributions:</p>
        
        <ol>
            <li><strong>The SPAK Architecture</strong>: A formalization of the dual-loop cognitive process for HPC engineering</li>
            <li><strong>Engineering Instruction Guides</strong>: A structured interface between strategic and tactical reasoning</li>
            <li><strong>Case Study Validation</strong>: Quantitative results demonstrating orders-of-magnitude improvements in real optimization tasks</li>
            <li><strong>Hardware Efficiency Analysis</strong>: Metrics showing reduced GPU utilization with improved outcomes</li>
        </ol>
    </div>
    
    <div class="section">
        <h2>2. The SPAK Architecture: Formal Specification</h2>
        
        <h3>3.1 Dual-Loop Structure</h3>
        
        <div class="figure">
            <pre>
┌─────────────────────────────────────────────────────┐
│               Strategic Loop (CPU)                   │
│               Abductive Reasoning                    │
├─────────────────────────────────────────────────────┤
│  Input: Problem Specification, Performance Goals    │
│  Process: Algorithm Design, Invariant Verification  │
│  Output: Engineering Instruction Guide              │
│  Verification: Mathematical Proof, Simulation       │
└──────────────────────────┬──────────────────────────┘
                           │
                    Engineering Instruction Guide
      (Formal interface with invariants, algorithm spec)
                           │
┌──────────────────────────▼──────────────────────────┐
│               Tactical Loop (GPU)                   │
│               Inductive Optimization                │
├─────────────────────────────────────────────────────┤
│  Input: Instruction Guide                          │
│  Process: Implementation, Auto-tuning              │
│  Output: Optimized Kernel, Performance Metrics     │
│  Verification: Numerical Correctness, Speedup      │
└─────────────────────────────────────────────────────┘
            </pre>
            <div class="figure-caption">그림 1: SPAK 듀얼-루프 아키텍처</div>
        </div>
        
        <h3>3.2 Engineering Instruction Guide: A Formal Interface</h3>
        <p>The Instruction Guide serves as the contract between loops:</p>
        
        <pre><code>@dataclass
class EngineeringInstructionGuide:
    """Formal specification for kernel implementation"""
    
    # Algorithm specification
    algorithm: AlgorithmDescription
    invariants: List[MathematicalInvariant]
    assumptions: List[SystemAssumption]
    
    # Performance targets
    complexity_bounds: ComputationalComplexity
    memory_constraints: MemoryHierarchySpecification
    
    # Implementation constraints
    hardware_target: GPUArchitecture
    programming_model: ProgrammingModelSpec
    
    # Verification requirements
    correctness_criteria: List[VerificationCriterion]
    performance_metrics: List[PerformanceMetric]
    
    def validate_implementation(self, kernel_code: str) -> ValidationResult:
        """Check if implementation satisfies all constraints"""
        return self._check_all_constraints(kernel_code)</code></pre>
        
        <h3>3.3 The Strategic Loop: Abductive Reasoning Process</h3>
        <p>Formally, the strategic loop performs:</p>
        
        <div class="equation">
            \[
            \text{Given: } \mathcal{P} \text{ (problem), } \mathcal{C} \text{ (constraints)}
            \]
            \[
            \text{Find: } \mathcal{H}^* = \arg\max_{\mathcal{H} \in \mathcal{H}} \text{Plausibility}(\mathcal{H} | \mathcal{P}, \mathcal{C})
            \]
        </div>
        
        <p>Where \(\mathcal{H}\) represents architectural hypotheses (e.g., "fusion eliminates O(N²) memory access").</p>
        
        <p><strong>Implementation Steps:</strong></p>
        <ol>
            <li><strong>Problem Decomposition</strong>: Break complex operations into primitive components</li>
            <li><strong>Invariant Identification</strong>: Derive mathematical properties that must hold</li>
            <li><strong>Hypothesis Generation</strong>: Propose architectural transformations</li>
            <li><strong>Simulation Verification</strong>: Validate hypotheses through bit-exact simulation</li>
            <li><strong>Instruction Generation</strong>: Create formal implementation guide</li>
        </ol>
        
        <h3>3.4 The Tactical Loop: Inductive Optimization Process</h3>
        <p>The tactical loop performs empirical search:</p>
        
        <div class="equation">
            \[
            \text{Given: } \mathcal{I} \text{ (instruction guide)}
            \]
            \[
            \text{Find: } \theta^* = \arg\min_{\theta \in \Theta} \text{Cost}(\text{Execute}(\text{Implement}(\mathcal{I}, \theta)))
            \]
        </div>
        
        <p>Where \(\theta\) represents implementation parameters (tile sizes, unrolling factors, etc.).</p>
        
        <p><strong>Implementation Steps:</strong></p>
        <ol>
            <li><strong>Code Generation</strong>: Translate instruction guide to hardware-specific code</li>
            <li><strong>Compilation & Debugging</strong>: Handle low-level implementation details</li>
            <li><strong>Parameter Sweeping</strong>: Search optimization space defined by instruction guide</li>
            <li><strong>Performance Measurement</strong>: Collect empirical performance data</li>
            <li><strong>Result Reporting</strong>: Provide structured feedback to strategic loop</li>
        </ol>
    </div>
    
    <div class="section">
        <h2>4. Case Studies: Quantitative Validation</h2>
        
        <h3>4.1 Case Study 1: Fused Multi-Head Attention Optimization</h3>
        <p><strong>Problem Complexity</strong>: \(O(N^2d)\) computation with \(O(N^2)\) intermediate memory</p>
        
        <p><strong>SPAK Process:</strong></p>
        <ol>
            <li><strong>Strategic Analysis (CPU)</strong>:
                <ul>
                    <li>Identified Online Softmax as key innovation</li>
                    <li>Proved numerical stability through Python simulation</li>
                    <li>Generated instruction guide for fused kernel implementation</li>
                </ul>
            </li>
            <li><strong>Tactical Implementation (GPU)</strong>:
                <ul>
                    <li>Implemented fused kernel with register tiling</li>
                    <li>Auto-tuned tile sizes (64×64 optimal for RTX 5070)</li>
                    <li>Achieved 113.73 TFLOPS</li>
                </ul>
            </li>
        </ol>
        
        <p><strong>Results:</strong></p>
        <table>
            <thead>
                <tr>
                    <th>Phase</th>
                    <th>Performance</th>
                    <th>Speedup</th>
                    <th>Key Innovation</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Naive</td>
                    <td>0.27 TFLOPS</td>
                    <td>1×</td>
                    <td>Baseline</td>
                </tr>
                <tr>
                    <td>Fused</td>
                    <td>38.30 TFLOPS</td>
                    <td>141×</td>
                    <td>Algorithmic (loop fusion)</td>
                </tr>
                <tr>
                    <td>Tuned</td>
                    <td>113.73 TFLOPS</td>
                    <td>421×</td>
                    <td>Hardware-specific optimization</td>
                </tr>
            </tbody>
        </table>
        
        <p><strong>Key Insight</strong>: The 141× speedup from fusion represents <strong>algorithmic innovation</strong> (changing computational complexity), while the additional 3× from tuning represents <strong>hardware optimization</strong> (parameter refinement).</p>
        
        <h3>4.2 Case Study 2: Matrix Multiplication Optimization</h3>
        <p><strong>Problem Complexity</strong>: Well-studied but hardware-sensitive</p>
        
        <p><strong>SPAK Process:</strong></p>
        <ol>
            <li><strong>Strategic Analysis</strong>:
                <ul>
                    <li>Identified pipelining as critical for Tensor Core utilization</li>
                    <li>Generated instruction guide with parameter search space</li>
                </ul>
            </li>
            <li><strong>Tactical Implementation</strong>:
                <ul>
                    <li>Implemented swizzling and double buffering</li>
                    <li>Auto-tuned to find optimal tile configuration</li>
                    <li>Achieved 66.90 TFLOPS (98% of cuBLAS)</li>
                </ul>
            </li>
        </ol>
        
        <p><strong>Results:</strong></p>
        <table>
            <thead>
                <tr>
                    <th>Optimization Level</th>
                    <th>TFLOPS</th>
                    <th>Efficiency</th>
                    <th>Key Technique</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Naive Tiling</td>
                    <td>20.55</td>
                    <td>30%</td>
                    <td>Basic decomposition</td>
                </tr>
                <tr>
                    <td>Optimized Occupancy</td>
                    <td>58.97</td>
                    <td>86%</td>
                    <td>CTA saturation</td>
                </tr>
                <tr>
                    <td>Full Optimization</td>
                    <td>66.90</td>
                    <td>98%</td>
                    <td>Pipelining + Auto-tuning</td>
                </tr>
            </tbody>
        </table>
        
        <p><strong>Key Insight</strong>: SPAK successfully navigated the complex optimization space, achieving near-optimal performance through systematic exploration rather than random search.</p>
        
        <h3>4.3 Hardware Efficiency Analysis</h3>
        <p>A critical benefit of SPAK is <strong>hardware utilization efficiency</strong>:</p>
        
        <pre><code>def calculate_hardware_efficiency(strategic_time, tactical_time):
    """
    Compare SPAK vs. naive approach
    """
    # Traditional approach: All work on GPU
    traditional_gpu_time = strategic_time + tactical_time
    
    # SPAK approach: Strategic work on CPU
    spak_gpu_time = tactical_time
    
    efficiency_gain = traditional_gpu_time / spak_gpu_time
    return efficiency_gain</code></pre>
        
        <p><strong>Results</strong>: SPAK reduced GPU utilization by 67% while improving final performance by 3.8× compared to end-to-end GPU-based optimization.</p>
    </div>
    
    <div class="section">
        <h2>5. Theoretical Contributions</h2>
        
        <h3>5.1 Formalization of Engineering Cognition</h3>
        <p>We provide the first formal model of HPC engineering as a <strong>dual-process cognitive system</strong>:</p>
        
        <p><strong>Theorem 1</strong> (Separation Efficiency): For optimization problems where strategic reasoning cost \(C_s\) is less than tactical search cost \(C_t\), separating the processes reduces total cost when:</p>
        
        <div class="equation">
            \[
            \frac{C_s}{\text{CPU\_cost}} + \frac{C_t}{\text{GPU\_cost}} < \frac{C_s + C_t}{\text{GPU\_cost}}
            \]
        </div>
        
        <p>Where CPU_cost ≪ GPU_cost.</p>
        
        <p><strong>Proof Sketch</strong>: Follows from the specialization of each resource type to its optimal task.</p>
        
        <h3>5.2 The Instruction Guide as Verification Interface</h3>
        <p>We introduce <strong>Engineering Instruction Guides</strong> as a novel intermediate representation that:</p>
        
        <ol>
            <li>Encodes architectural decisions separately from implementation details</li>
            <li>Provides verifiable contracts between reasoning phases</li>
            <li>Enables reuse of strategic insights across hardware generations</li>
        </ol>
        
        <h3>5.3 Cognitive Load Distribution</h3>
        <p>SPAK distributes cognitive load according to resource constraints:</p>
        <ul>
            <li><strong>CPU</strong>: Handles high-dimensional search (architectural space)</li>
            <li><strong>GPU</strong>: Handles empirical optimization (parameter space)</li>
        </ul>
        
        <p>This matches human expert behavior and hardware capabilities.</p>
    </div>
    
    <div class="section">
        <h2>6. Conclusion</h2>
        
        <p>The SPAK architecture demonstrates that <strong>systematic decomposition</strong> of the optimization process yields superior results to end-to-end approaches. By separating abductive architectural reasoning from inductive parameter optimization, and by using formal Engineering Instruction Guides as interfaces, we achieve:</p>
        
        <ol>
            <li><strong>Better Performance</strong>: 421× speedup in FMHA, near-cuBLAS performance in MatMul</li>
            <li><strong>Higher Efficiency</strong>: 67% reduction in expensive GPU resource utilization</li>
            <li><strong>Improved Verifiability</strong>: Clear verification points at each phase</li>
            <li><strong>Better Interpretability</strong>: Transparent reasoning process</li>
        </ol>
        
        <p>These results suggest that future AI-assisted engineering systems should move beyond monolithic code generation toward <strong>structured reasoning systems</strong> that mirror expert cognitive processes. The separation of concerns formalized in SPAK provides a roadmap for this evolution, offering both practical performance benefits and theoretical insights into the nature of computational engineering cognition.</p>
    </div>
    
    <div class="section">
        <h2>References</h2>
        
        <div class="reference">
            1. FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
        </div>
        <div class="reference">
            2. Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations
        </div>
        <div class="reference">
            3. The Architecture of Cognition: The Adaptive Control of Thought
        </div>
        <div class="reference">
            4. Abductive Reasoning: Logical Investigations into Discovery and Explanation
        </div>
        <div class="reference">
            5. Auto-tuning Techniques for High-Performance Computing Applications
        </div>
    </div>
    
    <div class="footnote">
        <p>© 2024 시스템 엔지니어링 AI 연구실. 이 논문은 연구 초안이며, 인용을 위한 공식 출판 버전이 아닙니다.</p>
        <p>문의: research@system-engineering.ai</p>
    </div>
    
    <script>
        // MathJax 구성
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
</body>
</html>